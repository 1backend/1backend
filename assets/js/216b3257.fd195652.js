"use strict";(self.webpackChunksingulatron_api_docs=self.webpackChunksingulatron_api_docs||[]).push([[2623],{16531:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"built-in-services/prompt-svc","title":"Prompt Svc","description":"The Prompt Svc is a resilient AI orchestration service that provides a unified interface for interacting with Large Language Models (LLMs) and other AI systems through a queue-based architecture with real-time streaming capabilities.","source":"@site/docs/built-in-services/prompt-svc.md","sourceDirName":"built-in-services","slug":"/built-in-services/prompt-svc","permalink":"/docs/built-in-services/prompt-svc","draft":false,"unlisted":false,"editUrl":"https://github.com/1backend/1backend/tree/main/docs-source/docs/built-in-services/prompt-svc.md","tags":[{"inline":true,"label":"prompt-svc","permalink":"/docs/tags/prompt-svc"},{"inline":true,"label":"prompts","permalink":"/docs/tags/prompts"},{"inline":true,"label":"ai","permalink":"/docs/tags/ai"},{"inline":true,"label":"llm","permalink":"/docs/tags/llm"},{"inline":true,"label":"streaming","permalink":"/docs/tags/streaming"},{"inline":true,"label":"queue","permalink":"/docs/tags/queue"},{"inline":true,"label":"text-generation","permalink":"/docs/tags/text-generation"},{"inline":true,"label":"image-generation","permalink":"/docs/tags/image-generation"},{"inline":true,"label":"real-time","permalink":"/docs/tags/real-time"}],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30,"tags":["prompt-svc","prompts","ai","llm","streaming","queue","text-generation","image-generation","real-time"]},"sidebar":"tutorialSidebar","previous":{"title":"Secret Svc","permalink":"/docs/built-in-services/secret-svc"},"next":{"title":"Registry Svc","permalink":"/docs/built-in-services/registry-svc"}}');var r=t(74848),o=t(28453);const a={sidebar_position:30,tags:["prompt-svc","prompts","ai","llm","streaming","queue","text-generation","image-generation","real-time"]},i="Prompt Svc",l={},p=[{value:"Architecture &amp; Purpose",id:"architecture--purpose",level:2},{value:"Key Features",id:"key-features",level:3},{value:"CLI Usage",id:"cli-usage",level:2},{value:"Text Generation (Synchronous)",id:"text-generation-synchronous",level:3},{value:"Text Generation (Asynchronous with Streaming)",id:"text-generation-asynchronous-with-streaming",level:3},{value:"Image Generation",id:"image-generation",level:3},{value:"Advanced Configuration",id:"advanced-configuration",level:3},{value:"Prompt Management",id:"prompt-management",level:3},{value:"Prompt Types &amp; Capabilities",id:"prompt-types--capabilities",level:2},{value:"Text Generation Types",id:"text-generation-types",level:3},{value:"Image Generation Types",id:"image-generation-types",level:3},{value:"Multimodal Types",id:"multimodal-types",level:3},{value:"Queue Architecture &amp; Processing",id:"queue-architecture--processing",level:2},{value:"Queue Flow",id:"queue-flow",level:3},{value:"Queue Management",id:"queue-management",level:3},{value:"Retry Logic",id:"retry-logic",level:3},{value:"Streaming &amp; Real-Time Responses",id:"streaming--real-time-responses",level:2},{value:"Server-Sent Events (SSE)",id:"server-sent-events-sse",level:3},{value:"JavaScript Integration",id:"javascript-integration",level:3},{value:"Stream Management",id:"stream-management",level:3},{value:"Parameter Systems",id:"parameter-systems",level:2},{value:"High-Level Parameters",id:"high-level-parameters",level:3},{value:"Engine-Specific Parameters",id:"engine-specific-parameters",level:3},{value:"Real-World Usage Examples",id:"real-world-usage-examples",level:2},{value:"1. Interactive Chatbot",id:"1-interactive-chatbot",level:3},{value:"2. Code Generation Pipeline",id:"2-code-generation-pipeline",level:3},{value:"3. Content Creation Workflow",id:"3-content-creation-workflow",level:3},{value:"4. Document Analysis System",id:"4-document-analysis-system",level:3},{value:"5. Creative AI Assistant",id:"5-creative-ai-assistant",level:3},{value:"6. Batch Processing System",id:"6-batch-processing-system",level:3},{value:"Integration Patterns",id:"integration-patterns",level:2},{value:"Chat Svc Integration",id:"chat-svc-integration",level:3},{value:"Model Svc Integration",id:"model-svc-integration",level:3},{value:"File Svc Integration",id:"file-svc-integration",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Synchronous vs Asynchronous",id:"synchronous-vs-asynchronous",level:3},{value:"Queue Optimization",id:"queue-optimization",level:3},{value:"Model Selection",id:"model-selection",level:3},{value:"Monitoring &amp; Observability",id:"monitoring--observability",level:2},{value:"Queue Status Monitoring",id:"queue-status-monitoring",level:3},{value:"Performance Analytics",id:"performance-analytics",level:3},{value:"Health Checking",id:"health-checking",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"<strong>Prompts Stuck in Queue</strong>",id:"prompts-stuck-in-queue",level:4},{value:"<strong>Streaming Not Working</strong>",id:"streaming-not-working",level:4},{value:"<strong>High Retry Counts</strong>",id:"high-retry-counts",level:4},{value:"<strong>Memory/Performance Issues</strong>",id:"memoryperformance-issues",level:4},{value:"Debug Commands",id:"debug-commands",level:3},{value:"Template System",id:"template-system",level:2},{value:"Prompt Templates",id:"prompt-templates",level:3},{value:"Template Variables",id:"template-variables",level:3},{value:"API Reference Summary",id:"api-reference-summary",level:2},{value:"Permissions &amp; Security",id:"permissions--security",level:2},{value:"Related Services",id:"related-services",level:2},{value:"Future Enhancements",id:"future-enhancements",level:2},{value:"Planned Features",id:"planned-features",level:3},{value:"Integration Roadmap",id:"integration-roadmap",level:3}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"prompt-svc",children:"Prompt Svc"})}),"\n",(0,r.jsx)(n.p,{children:"The Prompt Svc is a resilient AI orchestration service that provides a unified interface for interacting with Large Language Models (LLMs) and other AI systems through a queue-based architecture with real-time streaming capabilities."}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["This page provides a comprehensive overview of ",(0,r.jsx)(n.code,{children:"Prompt Svc"}),". For detailed API information, refer to the ",(0,r.jsx)(n.a,{href:"/docs/1backend-api/prompt",children:"Prompt Svc API documentation"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"architecture--purpose",children:"Architecture & Purpose"}),"\n",(0,r.jsxs)(n.p,{children:["Prompt Svc serves as the ",(0,r.jsx)(n.strong,{children:"AI interaction layer"})," for 1Backend, providing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Unified Interface"}),": Single API for all AI model interactions (text, image, audio)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Queue Management"}),": Resilient processing with automatic retries and exponential backoff"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time Streaming"}),": Live response streaming via Server-Sent Events (SSE)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Modal Support"}),": Text-to-text, text-to-image, image-to-image, and more"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Platform Abstraction"}),": Support for different AI engines (LlamaCpp, Stable Diffusion)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Integration Layer"}),": Seamless connection with Chat Svc and Model Svc"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Asynchronous Processing"}),": Queue-based prompt handling with status tracking"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronous Mode"}),": Blocking calls for scripting and simple integrations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Streaming Responses"}),": Real-time output streaming for progressive results"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Retry Logic"}),": Automatic retry with exponential backoff for failed prompts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Template System"}),": Flexible prompt templates for different model formats"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Platform"}),": Engine-agnostic and engine-specific parameter support"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"cli-usage",children:"CLI Usage"}),"\n",(0,r.jsx)(n.p,{children:"Prompt Svc provides both synchronous and asynchronous interaction modes:"}),"\n",(0,r.jsx)(n.h3,{id:"text-generation-synchronous",children:"Text Generation (Synchronous)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Simple text generation with default model\noo post /prompt-svc/prompt \\\n  --prompt="Explain quantum computing in simple terms" \\\n  --sync=true\n\n# With specific model\noo post /prompt-svc/prompt \\\n  --prompt="Write a Python function to calculate Fibonacci numbers" \\\n  --modelId="huggingface/TheBloke/codellama-7b.Q4_K_M.gguf" \\\n  --sync=true\n\n# Using high-level parameters\noo post /prompt-svc/prompt \\\n  --prompt="Hello, how are you?" \\\n  --parameters.textToText.template="[INST] {prompt} [/INST]" \\\n  --sync=true\n\n# Using engine-specific parameters  \noo post /prompt-svc/prompt \\\n  --prompt="What is the meaning of life?" \\\n  --engineParameters.llamaCpp.template="### HUMAN:\\n{prompt}\\n\\n### RESPONSE:\\n" \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h3,{id:"text-generation-asynchronous-with-streaming",children:"Text Generation (Asynchronous with Streaming)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Submit prompt to queue\noo post /prompt-svc/prompt \\\n  --prompt="Write a detailed essay about artificial intelligence" \\\n  --threadId="thread_12345" \\\n  --sync=false\n\n# Subscribe to streaming responses (in another terminal)\ncurl -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/thread_12345/responses/subscribe"\n\n# Or using Server-Sent Events in JavaScript\n# const eventSource = new EventSource(\'/prompt-svc/prompts/thread_12345/responses/subscribe\');\n'})}),"\n",(0,r.jsx)(n.h3,{id:"image-generation",children:"Image Generation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Text-to-image with Stable Diffusion\noo post /prompt-svc/prompt \\\n  --prompt="A serene mountain landscape at sunset, digital art" \\\n  --parameters.textToImage.width=512 \\\n  --parameters.textToImage.height=512 \\\n  --parameters.textToImage.steps=20 \\\n  --sync=true\n\n# Using Stable Diffusion engine parameters\noo post /prompt-svc/prompt \\\n  --prompt="A futuristic city with flying cars" \\\n  --engineParameters.stableDiffusion.txt2Img.width=768 \\\n  --engineParameters.stableDiffusion.txt2Img.height=768 \\\n  --engineParameters.stableDiffusion.txt2Img.num_inference_steps=30 \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-configuration",children:"Advanced Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# With retry configuration and thread management\noo post /prompt-svc/prompt \\\n  --prompt="Analyze this business case and provide recommendations" \\\n  --threadId="business_analysis_001" \\\n  --maxRetries=5 \\\n  --modelId="huggingface/TheBloke/mistral-7b-instruct-v0.2.Q4_K_M.gguf" \\\n  --sync=false\n\n# Custom prompt ID (for idempotency)\noo post /prompt-svc/prompt \\\n  --id="prom_custom_12345" \\\n  --prompt="Generate a summary of the latest AI research" \\\n  --threadId="ai_research_summary" \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h3,{id:"prompt-management",children:"Prompt Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# List active prompts\noo post /prompt-svc/prompts\n\n# List prompts with specific status\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "running"}]\'\n\n# Remove a prompt from queue\noo delete /prompt-svc/prompt/prom_12345\n\n# List prompts for specific thread\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "threadId", "operator": "equals", "value": "thread_12345"}]\'\n'})}),"\n",(0,r.jsx)(n.h2,{id:"prompt-types--capabilities",children:"Prompt Types & Capabilities"}),"\n",(0,r.jsx)(n.h3,{id:"text-generation-types",children:"Text Generation Types"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# General text-to-text\nType: "Text-to-Text"\nUse: General language tasks, conversations, analysis\n\n# Question answering\nType: "Question Answering" \nUse: Specific questions with factual answers\n\n# Translation\nType: "Translation"\nUse: Language translation tasks\n\n# Summarization\nType: "Summarization"\nUse: Text summarization and condensation\n\n# Text generation\nType: "Text Generation"\nUse: Creative writing, code generation\n'})}),"\n",(0,r.jsx)(n.h3,{id:"image-generation-types",children:"Image Generation Types"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Text-to-image\nType: "Text-to-Image"\nUse: Generate images from text descriptions\n\n# Image-to-image\nType: "Image-to-Image" \nUse: Transform existing images based on prompts\n\n# Unconditional image generation\nType: "Unconditional Image Generation"\nUse: Generate random images without prompts\n'})}),"\n",(0,r.jsx)(n.h3,{id:"multimodal-types",children:"Multimodal Types"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Image-text-to-text\nType: "Image-Text-to-Text"\nUse: Analyze images with text context\n\n# Visual question answering\nType: "Visual Question Answering"\nUse: Answer questions about images\n\n# Document question answering\nType: "Document Question Answering"\nUse: Extract information from document images\n'})}),"\n",(0,r.jsx)(n.h2,{id:"queue-architecture--processing",children:"Queue Architecture & Processing"}),"\n",(0,r.jsx)(n.h3,{id:"queue-flow",children:"Queue Flow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-mermaid",children:"sequenceDiagram\n    participant Client\n    participant PS as Prompt Svc\n    participant Queue as Prompt Queue\n    participant MS as Model Svc\n    participant AI as AI Engine\n    participant CS as Chat Svc\n    \n    Client->>PS: Submit Prompt\n    PS->>Queue: Add to Queue\n    PS--\x3e>Client: Return Prompt ID\n    \n    loop Process Queue\n        PS->>Queue: Get Next Prompt\n        PS->>MS: Get Model Status\n        MS--\x3e>PS: Model Address\n        PS->>AI: Send Prompt\n        AI--\x3e>PS: Stream Response\n        PS->>CS: Save Message\n        PS--\x3e>Client: Stream Chunks (SSE)\n    end\n"})}),"\n",(0,r.jsx)(n.h3,{id:"queue-management",children:"Queue Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Monitor queue status\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "in", "value": ["scheduled", "running"]}]\'\n\n# Check retry behavior\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "errored"}]\'\n\n# Performance monitoring\noo post /prompt-svc/prompts \\\n  --query.orderBy=\'[{"field": "createdAt", "desc": true}]\' \\\n  --query.limit=10\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Queue Status Values:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"scheduled"}),": Waiting in queue for processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"running"}),": Currently being processed by AI engine"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"completed"}),": Successfully finished"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"errored"}),": Failed but will be retried"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"abandoned"}),": Failed after max retries"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"canceled"}),": Manually canceled"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"retry-logic",children:"Retry Logic"}),"\n",(0,r.jsx)(n.p,{children:"Prompts that fail are automatically retried with exponential backoff:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Configure retry behavior\noo post /prompt-svc/prompt \\\n  --prompt="Complex analysis task" \\\n  --maxRetries=5 \\\n  --sync=false\n\n# Default retry strategy:\n# Attempt 1: Immediate\n# Attempt 2: 2 seconds delay  \n# Attempt 3: 4 seconds delay\n# Attempt 4: 8 seconds delay\n# Attempt 5: 16 seconds delay\n'})}),"\n",(0,r.jsx)(n.h2,{id:"streaming--real-time-responses",children:"Streaming & Real-Time Responses"}),"\n",(0,r.jsx)(n.h3,{id:"server-sent-events-sse",children:"Server-Sent Events (SSE)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Subscribe to thread streaming\ncurl -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/thread_12345/responses/subscribe"\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Stream Event Types:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'// Progress chunk (partial response)\n{\n  "text": "Quantum computing is a revolutionary",\n  "type": "progress"\n}\n\n// Done chunk (completion)\n{\n  "text": " technology that uses quantum mechanics.",\n  "messageId": "msg_abc123",\n  "type": "done"\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"javascript-integration",children:"JavaScript Integration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Real-time streaming in web applications\nconst eventSource = new EventSource(\n  '/prompt-svc/prompts/thread_12345/responses/subscribe',\n  {\n    headers: {\n      'Authorization': 'Bearer ' + token\n    }\n  }\n);\n\neventSource.onmessage = function(event) {\n  const chunk = JSON.parse(event.data);\n  \n  if (chunk.type === 'progress') {\n    // Append text to UI\n    appendToOutput(chunk.text);\n  } else if (chunk.type === 'done') {\n    // Response complete\n    finalizeOutput(chunk.messageId);\n  }\n};\n"})}),"\n",(0,r.jsx)(n.h3,{id:"stream-management",children:"Stream Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Pre-subscribe to threads (before prompt submission)\ncurl -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/future_thread/responses/subscribe" &\n\n# Then submit prompt to that thread\noo post /prompt-svc/prompt \\\n  --prompt="Generate a story" \\\n  --threadId="future_thread" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h2,{id:"parameter-systems",children:"Parameter Systems"}),"\n",(0,r.jsx)(n.h3,{id:"high-level-parameters",children:"High-Level Parameters"}),"\n",(0,r.jsx)(n.p,{children:"Use these when you don't care about the specific AI engine:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Text-to-text parameters\noo post /prompt-svc/prompt \\\n  --prompt="Hello world" \\\n  --parameters.textToText.template="[INST] {prompt} [/INST]"\n\n# Text-to-image parameters\noo post /prompt-svc/prompt \\\n  --prompt="A beautiful sunset" \\\n  --parameters.textToImage.width=512 \\\n  --parameters.textToImage.height=512 \\\n  --parameters.textToImage.steps=20 \\\n  --parameters.textToImage.guidanceScale=7.5\n'})}),"\n",(0,r.jsx)(n.h3,{id:"engine-specific-parameters",children:"Engine-Specific Parameters"}),"\n",(0,r.jsx)(n.p,{children:"Use these for fine-tuned control over specific AI engines:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# LlamaCpp engine parameters\noo post /prompt-svc/prompt \\\n  --prompt="What is AI?" \\\n  --engineParameters.llamaCpp.template="### HUMAN:\\n{prompt}\\n\\n### RESPONSE:\\n"\n\n# Stable Diffusion engine parameters\noo post /prompt-svc/prompt \\\n  --prompt="A spaceship" \\\n  --engineParameters.stableDiffusion.txt2Img.width=768 \\\n  --engineParameters.stableDiffusion.txt2Img.height=768 \\\n  --engineParameters.stableDiffusion.txt2Img.num_inference_steps=30 \\\n  --engineParameters.stableDiffusion.txt2Img.guidance_scale=8.0 \\\n  --engineParameters.stableDiffusion.txt2Img.negative_prompt="blurry, low quality"\n'})}),"\n",(0,r.jsx)(n.h2,{id:"real-world-usage-examples",children:"Real-World Usage Examples"}),"\n",(0,r.jsx)(n.h3,{id:"1-interactive-chatbot",children:"1. Interactive Chatbot"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Start chat session\nTHREAD_ID="chat_session_$(date +%s)"\n\n# Set up streaming in background\ncurl -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/$THREAD_ID/responses/subscribe" &\n\n# Send messages\noo post /prompt-svc/prompt \\\n  --prompt="Hello! I need help with Python programming." \\\n  --threadId="$THREAD_ID" \\\n  --sync=false\n\noo post /prompt-svc/prompt \\\n  --prompt="How do I create a simple web server?" \\\n  --threadId="$THREAD_ID" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-code-generation-pipeline",children:"2. Code Generation Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Use CodeLlama for programming tasks\nCODE_MODEL="huggingface/TheBloke/codellama-7b.Q4_K_M.gguf"\n\n# Generate function\noo post /prompt-svc/prompt \\\n  --prompt="Write a Python function that calculates the factorial of a number" \\\n  --modelId="$CODE_MODEL" \\\n  --sync=true\n\n# Generate tests\noo post /prompt-svc/prompt \\\n  --prompt="Write unit tests for the factorial function above" \\\n  --modelId="$CODE_MODEL" \\\n  --threadId="code_generation_session" \\\n  --sync=true\n\n# Generate documentation  \noo post /prompt-svc/prompt \\\n  --prompt="Write docstring documentation for the factorial function" \\\n  --modelId="$CODE_MODEL" \\\n  --threadId="code_generation_session" \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-content-creation-workflow",children:"3. Content Creation Workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Research phase\noo post /prompt-svc/prompt \\\n  --prompt="Research the latest trends in renewable energy technology" \\\n  --threadId="content_creation_001" \\\n  --sync=false\n\n# Writing phase\noo post /prompt-svc/prompt \\\n  --prompt="Write a 500-word article about solar panel efficiency improvements" \\\n  --threadId="content_creation_001" \\\n  --maxRetries=3 \\\n  --sync=false\n\n# Image generation for article\noo post /prompt-svc/prompt \\\n  --prompt="Solar panels on a modern house roof, bright sunny day, professional photography" \\\n  --parameters.textToImage.width=1024 \\\n  --parameters.textToImage.height=768 \\\n  --threadId="content_creation_001" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h3,{id:"4-document-analysis-system",children:"4. Document Analysis System"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Analyze uploaded documents\nANALYSIS_THREAD="doc_analysis_$(date +%s)"\n\n# Set up streaming for real-time results\ncurl -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/$ANALYSIS_THREAD/responses/subscribe" > analysis_output.txt &\n\n# Submit analysis prompts\noo post /prompt-svc/prompt \\\n  --prompt="Summarize the key points in this financial report" \\\n  --threadId="$ANALYSIS_THREAD" \\\n  --sync=false\n\noo post /prompt-svc/prompt \\\n  --prompt="Extract all financial figures and create a table" \\\n  --threadId="$ANALYSIS_THREAD" \\\n  --sync=false\n\noo post /prompt-svc/prompt \\\n  --prompt="Identify potential risks mentioned in the document" \\\n  --threadId="$ANALYSIS_THREAD" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h3,{id:"5-creative-ai-assistant",children:"5. Creative AI Assistant"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Story generation with multiple prompts\nSTORY_THREAD="creative_story_$(date +%s)"\n\n# Character development\noo post /prompt-svc/prompt \\\n  --prompt="Create a detailed character profile for a space explorer" \\\n  --threadId="$STORY_THREAD" \\\n  --sync=false\n\n# Plot outline\noo post /prompt-svc/prompt \\\n  --prompt="Create a plot outline for a science fiction adventure" \\\n  --threadId="$STORY_THREAD" \\\n  --sync=false\n\n# Generate artwork\noo post /prompt-svc/prompt \\\n  --prompt="Space explorer in futuristic suit standing on alien planet, concept art style" \\\n  --parameters.textToImage.width=768 \\\n  --parameters.textToImage.height=1024 \\\n  --threadId="$STORY_THREAD" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h3,{id:"6-batch-processing-system",children:"6. Batch Processing System"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Process multiple prompts with queue management\nBATCH_THREAD="batch_processing_$(date +%s)"\n\n# Submit batch of prompts\nprompts=(\n  "Analyze customer sentiment in this review: \'Great product, fast delivery\'"\n  "Translate to Spanish: \'Welcome to our customer support\'"\n  "Summarize: \'The quarterly earnings report shows...\'"\n  "Generate email template for customer onboarding"\n)\n\nfor i in "${!prompts[@]}"; do\n  oo post /prompt-svc/prompt \\\n    --id="batch_item_$i" \\\n    --prompt="${prompts[$i]}" \\\n    --threadId="$BATCH_THREAD" \\\n    --maxRetries=2 \\\n    --sync=false\n  \n  echo "Submitted batch item $i"\ndone\n\n# Monitor batch progress\nwatch -n 5 "oo post /prompt-svc/prompts --query.filters=\'[{\\"field\\": \\"threadId\\", \\"operator\\": \\"equals\\", \\"value\\": \\"$BATCH_THREAD\\"}]\' | jq \'.prompts[] | {id, status}\'"\n'})}),"\n",(0,r.jsx)(n.h2,{id:"integration-patterns",children:"Integration Patterns"}),"\n",(0,r.jsx)(n.h3,{id:"chat-svc-integration",children:"Chat Svc Integration"}),"\n",(0,r.jsxs)(n.p,{children:["Prompt Svc automatically integrates with ",(0,r.jsx)(n.a,{href:"/docs/built-in-services/chat-svc",children:"Chat Svc"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Create chat thread\nCHAT_THREAD=$(oo post /chat-svc/thread \\\n  --threadData.title="AI Assistant Chat" | jq -r \'.thread.id\')\n\n# Send prompt (automatically creates chat messages)\noo post /prompt-svc/prompt \\\n  --prompt="Hello! Can you help me learn Python?" \\\n  --threadId="$CHAT_THREAD" \\\n  --sync=false\n\n# View chat history\noo post /chat-svc/thread/$CHAT_THREAD/messages\n'})}),"\n",(0,r.jsx)(n.h3,{id:"model-svc-integration",children:"Model Svc Integration"}),"\n",(0,r.jsx)(n.p,{children:"Automatic model management and status checking:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Check model status before prompting\noo get /model-svc/default-model/status\n\n# Use specific model (Prompt Svc handles model communication)\noo post /prompt-svc/prompt \\\n  --prompt="Generate code documentation" \\\n  --modelId="huggingface/TheBloke/codellama-7b.Q4_K_M.gguf" \\\n  --sync=true\n\n# Fallback to default model if modelId not specified\noo post /prompt-svc/prompt \\\n  --prompt="What\'s the weather like?" \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h3,{id:"file-svc-integration",children:"File Svc Integration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Upload image for analysis\nFILE_ID=$(curl -X PUT "http://localhost:11337/file-svc/upload" \\\n  -H "Authorization: Bearer $TOKEN" \\\n  -F "file=@./image.jpg" | jq -r \'.upload.fileId\')\n\n# Analyze uploaded image (future feature)\noo post /prompt-svc/prompt \\\n  --prompt="Describe what you see in this image" \\\n  --fileIds=\'["\'$FILE_ID\'"]\' \\\n  --sync=true\n'})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"synchronous-vs-asynchronous",children:"Synchronous vs Asynchronous"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Use sync=true for:\n# - Simple scripts\n# - Testing and development  \n# - Short responses\n\noo post /prompt-svc/prompt \\\n  --prompt="What is 2+2?" \\\n  --sync=true\n\n# Use sync=false for:\n# - Long-running tasks\n# - Web applications\n# - Batch processing\n\noo post /prompt-svc/prompt \\\n  --prompt="Write a detailed research paper on quantum computing" \\\n  --threadId="research_paper_001" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h3,{id:"queue-optimization",children:"Queue Optimization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Monitor queue depth\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "scheduled"}]\' \\\n  --query.count=true | jq \'.count\'\n\n# Prioritize urgent prompts (submit to dedicated threads)\noo post /prompt-svc/prompt \\\n  --prompt="URGENT: System security analysis needed" \\\n  --threadId="priority_processing" \\\n  --sync=false\n\n# Batch similar prompts for efficiency\nBATCH_THREAD="text_analysis_batch"\nfor text in "text1" "text2" "text3"; do\n  oo post /prompt-svc/prompt \\\n    --prompt="Analyze sentiment: $text" \\\n    --threadId="$BATCH_THREAD" \\\n    --sync=false\ndone\n'})}),"\n",(0,r.jsx)(n.h3,{id:"model-selection",children:"Model Selection"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Use lightweight models for simple tasks\noo post /prompt-svc/prompt \\\n  --prompt="Hello, how are you?" \\\n  --modelId="huggingface/TheBloke/tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf" \\\n  --sync=true\n\n# Use powerful models for complex tasks\noo post /prompt-svc/prompt \\\n  --prompt="Analyze this complex business scenario and provide strategic recommendations" \\\n  --modelId="huggingface/TheBloke/mistral-7b-instruct-v0.2.Q5_K_M.gguf" \\\n  --sync=false\n'})}),"\n",(0,r.jsx)(n.h2,{id:"monitoring--observability",children:"Monitoring & Observability"}),"\n",(0,r.jsx)(n.h3,{id:"queue-status-monitoring",children:"Queue Status Monitoring"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Real-time queue monitoring\nmonitor_queue() {\n  while true; do\n    echo "=== Queue Status $(date) ==="\n    \n    # Count by status\n    for status in "scheduled" "running" "completed" "errored"; do\n      count=$(oo post /prompt-svc/prompts \\\n        --query.filters=\'[{"field": "status", "operator": "equals", "value": "\'$status\'"}]\' \\\n        --query.count=true | jq \'.count\')\n      echo "$status: $count"\n    done\n    \n    echo "---"\n    sleep 10\n  done\n}\n\nmonitor_queue\n'})}),"\n",(0,r.jsx)(n.h3,{id:"performance-analytics",children:"Performance Analytics"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Response time analysis\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "completed"}]\' \\\n  --query.orderBy=\'[{"field": "createdAt", "desc": true}]\' \\\n  --query.limit=10 | jq \'.prompts[] | {id, created: .createdAt, lastRun: .lastRun, runCount}\'\n\n# Error analysis\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "in", "value": ["errored", "abandoned"]}]\' | \\\n  jq \'.prompts[] | {id, error, runCount, status}\'\n\n# Thread activity\noo post /prompt-svc/prompts \\\n  --query.orderBy=\'[{"field": "createdAt", "desc": true}]\' \\\n  --query.limit=20 | jq \'.prompts | group_by(.threadId) | map({thread: .[0].threadId, count: length})\'\n'})}),"\n",(0,r.jsx)(n.h3,{id:"health-checking",children:"Health Checking"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Test basic functionality\ntest_prompt_health() {\n  echo "Testing Prompt Svc health..."\n  \n  # Submit test prompt\n  response=$(oo post /prompt-svc/prompt \\\n    --prompt="Test prompt for health check" \\\n    --sync=true)\n  \n  if echo "$response" | jq -e \'.prompt.id\' > /dev/null; then\n    echo "\u2705 Prompt Svc is healthy"\n  else\n    echo "\u274c Prompt Svc health check failed"\n    echo "$response"\n  fi\n}\n\ntest_prompt_health\n'})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,r.jsx)(n.h4,{id:"prompts-stuck-in-queue",children:(0,r.jsx)(n.strong,{children:"Prompts Stuck in Queue"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Check queue status\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "scheduled"}]\'\n\n# Check model status\noo get /model-svc/default-model/status\n\n# Restart processing by canceling and resubmitting\noo delete /prompt-svc/prompt/STUCK_PROMPT_ID\n'})}),"\n",(0,r.jsx)(n.h4,{id:"streaming-not-working",children:(0,r.jsx)(n.strong,{children:"Streaming Not Working"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Test SSE connection\ncurl -v -N -H "Authorization: Bearer $TOKEN" \\\n  "http://localhost:11337/prompt-svc/prompts/test_thread/responses/subscribe"\n\n# Check firewall/proxy settings\n# Ensure Server-Sent Events are not blocked\n'})}),"\n",(0,r.jsx)(n.h4,{id:"high-retry-counts",children:(0,r.jsx)(n.strong,{children:"High Retry Counts"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Identify problematic prompts\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "runCount", "operator": "gt", "value": 3}]\'\n\n# Check model errors\noo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "equals", "value": "errored"}]\' | \\\n  jq \'.prompts[] | {id, error, runCount}\'\n\n# Verify model is responding\ncurl http://localhost:8001/health\n'})}),"\n",(0,r.jsx)(n.h4,{id:"memoryperformance-issues",children:(0,r.jsx)(n.strong,{children:"Memory/Performance Issues"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Monitor queue depth\nQUEUE_SIZE=$(oo post /prompt-svc/prompts \\\n  --query.filters=\'[{"field": "status", "operator": "in", "value": ["scheduled", "running"]}]\' \\\n  --query.count=true | jq \'.count\')\n\necho "Queue depth: $QUEUE_SIZE"\n\n# Clear completed prompts (if needed)\n# Note: This is manual - no automated cleanup yet\n'})}),"\n",(0,r.jsx)(n.h3,{id:"debug-commands",children:"Debug Commands"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Detailed prompt inspection\ndebug_prompt() {\n  local prompt_id=$1\n  echo "=== Debug Prompt: $prompt_id ==="\n  \n  oo post /prompt-svc/prompts \\\n    --query.filters=\'[{"field": "id", "operator": "equals", "value": "\'$prompt_id\'"}]\' | \\\n    jq \'.prompts[0] | {\n      id, status, prompt, threadId, modelId, \n      runCount, error, createdAt, lastRun\n    }\'\n}\n\n# Usage\ndebug_prompt "prom_12345"\n\n# Stream testing\ntest_streaming() {\n  local thread_id="test_stream_$(date +%s)"\n  \n  echo "Testing streaming for thread: $thread_id"\n  \n  # Start streaming in background\n  curl -N -H "Authorization: Bearer $TOKEN" \\\n    "http://localhost:11337/prompt-svc/prompts/$thread_id/responses/subscribe" &\n  \n  local curl_pid=$!\n  \n  # Submit test prompt\n  oo post /prompt-svc/prompt \\\n    --prompt="Count from 1 to 5" \\\n    --threadId="$thread_id" \\\n    --sync=false\n  \n  # Wait and cleanup\n  sleep 10\n  kill $curl_pid 2>/dev/null\n}\n\ntest_streaming\n'})}),"\n",(0,r.jsx)(n.h2,{id:"template-system",children:"Template System"}),"\n",(0,r.jsx)(n.h3,{id:"prompt-templates",children:"Prompt Templates"}),"\n",(0,r.jsx)(n.p,{children:"Different models require different prompt formats:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Mistral format\noo post /prompt-svc/prompt \\\n  --prompt="What is machine learning?" \\\n  --parameters.textToText.template="[INST] {prompt} [/INST]"\n\n# Llama2 format  \noo post /prompt-svc/prompt \\\n  --prompt="Explain neural networks" \\\n  --parameters.textToText.template="### HUMAN:\\n{prompt}\\n\\n### RESPONSE:\\n"\n\n# TinyLlama format\noo post /prompt-svc/prompt \\\n  --prompt="Hello world" \\\n  --parameters.textToText.template="<|system|>\\nYou are a helpful assistant.</s>\\n<|user|>\\n{prompt}</s>\\n<|assistant|>"\n\n# Auto-detection (uses model\'s default template)\noo post /prompt-svc/prompt \\\n  --prompt="Default template test" \\\n  --modelId="huggingface/TheBloke/mistral-7b-instruct-v0.2.Q4_K_M.gguf"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"template-variables",children:"Template Variables"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Custom template with system message\noo post /prompt-svc/prompt \\\n  --prompt="Write code comments" \\\n  --parameters.textToText.template="<|system|>\\nYou are a code documentation expert.</s>\\n<|user|>\\n{prompt}</s>\\n<|assistant|>"\n\n# Multi-variable templates (future feature)\n# template: "Context: {context}\\nQuestion: {prompt}\\nAnswer:"\n'})}),"\n",(0,r.jsx)(n.h2,{id:"api-reference-summary",children:"API Reference Summary"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Endpoint"}),(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Purpose"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/prompt-svc/prompt"})}),(0,r.jsx)(n.td,{children:"POST"}),(0,r.jsx)(n.td,{children:"Submit prompt for processing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/prompt-svc/prompts"})}),(0,r.jsx)(n.td,{children:"POST"}),(0,r.jsx)(n.td,{children:"List prompts with filtering"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/prompt-svc/prompt/{promptId}"})}),(0,r.jsx)(n.td,{children:"DELETE"}),(0,r.jsx)(n.td,{children:"Remove prompt from queue"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/prompt-svc/prompts/{threadId}/responses/subscribe"})}),(0,r.jsx)(n.td,{children:"GET"}),(0,r.jsx)(n.td,{children:"Subscribe to streaming responses"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/prompt-svc/types"})}),(0,r.jsx)(n.td,{children:"POST"}),(0,r.jsx)(n.td,{children:"Get type definitions (for API docs)"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"permissions--security",children:"Permissions & Security"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Required permissions\nprompt-svc:prompt:create    # Submit prompts\nprompt-svc:prompt:view      # List and view prompts  \nprompt-svc:prompt:stream    # Subscribe to streaming responses\nprompt-svc:prompt:delete    # Remove prompts from queue\n\n# Privacy protection\n# Users can only see their own prompts (prompt text hidden for others)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"related-services",children:"Related Services"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/built-in-services/model-svc",children:"Model Svc"})}),": AI model management and status"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/built-in-services/chat-svc",children:"Chat Svc"})}),": Conversation threading and message storage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/built-in-services/file-svc",children:"File Svc"})}),": File attachments and image inputs (future)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"/docs/built-in-services/policy-svc",children:"Policy Svc"})}),": Rate limiting AI usage"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"future-enhancements",children:"Future Enhancements"}),"\n",(0,r.jsx)(n.h3,{id:"planned-features",children:"Planned Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Model Orchestration"}),": Automatic model selection based on prompt type"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Auto-Scaling"}),": Start/stop models based on queue depth"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"File Input Support"}),": Image/document analysis with file uploads"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt Chaining"}),": Connect multiple prompts in workflows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Custom Templates"}),": User-defined prompt templates"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"integration-roadmap",children:"Integration Roadmap"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Voice Integration"}),": Audio-to-text and text-to-speech capabilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visual Processing"}),": Advanced image analysis and generation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Workflow Engine"}),": Complex multi-step AI workflows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A/B Testing"}),": Compare different models/prompts for same task"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analytics Dashboard"}),": Detailed usage and performance metrics"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Prompt Svc provides the essential AI interaction layer for 1Backend, enabling everything from simple chatbots to complex AI workflows with real-time streaming and robust queue management."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var s=t(96540);const r={},o=s.createContext(r);function a(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);