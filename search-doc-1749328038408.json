{"searchDocs":[{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":null},{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":null},{"title":"1Backend","type":0,"sectionRef":"#","url":"/docs/1backend/1-backend","content":"Version: 0.6.1 Export OpenAPI Spec 1Backend AI-native microservices platform. Authentication​ API Key: BearerAuth Type &quot;Bearer&quot; followed by a space and token acquired from the User Svc Login endpoint. Security Scheme Type: apiKey Header parameter name: Authorization Contact API Support: sales@singulatron.com URL: http://1backend.com/ Terms of Service http://swagger.io/terms/ License AGPL v3.0","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Change Password","type":0,"sectionRef":"#","url":"/docs/1backend/change-password","content":"Change Password POST /user-svc/change-password Allows an authenticated user to change their own password. Request​ Responses​ 200400401500 Password changed successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Build an Image","type":0,"sectionRef":"#","url":"/docs/1backend/build-image","content":"Build an Image PUT /container-svc/image Builds a Docker image with the specified parameters. Requires the container-svc:image:build permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Check","type":0,"sectionRef":"#","url":"/docs/1backend/check","content":"Check POST /policy-svc/check Check records a resource access and returns if the access is allowed. Request​ Responses​ 200400401500 Checked successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Checkout a git repository","type":0,"sectionRef":"#","url":"/docs/1backend/checkout-repo","content":"Checkout a git repository POST /source-svc/repo/checkout Checkout a git repository over https or ssh at a specific version into a temporary directory. Performs a shallow clone with minimal history for faster checkout. Request​ Responses​ 200400401500 Successfully checked out the repository","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Check If a Container Is Running","type":0,"sectionRef":"#","url":"/docs/1backend/container-is-running","content":"Check If a Container Is Running GET /container-svc/container/is-running Check if a Docker container is running, identified by hash or name. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Container Daemon Information","type":0,"sectionRef":"#","url":"/docs/1backend/container-daemon-info","content":"Get Container Daemon Information GET /container-svc/daemon/info Retrieve detailed information about the availability and status of container daemons on the node. Responses​ 200401500 Service Information","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Container Summary","type":0,"sectionRef":"#","url":"/docs/1backend/container-summary","content":"Get Container Summary GET /container-svc/container/summary Get a summary of the Docker container identified by hash or name, limited to a specified number of lines. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Create a Generic Object","type":0,"sectionRef":"#","url":"/docs/1backend/create-object","content":"Create a Generic Object POST /data-svc/object Creates a new object with the provided details. Requires authorization and user authentication. Request​ Responses​ 200400401500 Success","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Decrypt a Value","type":0,"sectionRef":"#","url":"/docs/1backend/decrypt-value","content":"Decrypt a Value POST /secret-svc/decrypt Decrypt a value and return the encrypted result Request​ Responses​ 200400401500 Decrypt Value Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete Deployment","type":0,"sectionRef":"#","url":"/docs/1backend/delete-deployment","content":"Delete Deployment DELETE /deploy-svc/deployment Delete a deployment. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete Definition","type":0,"sectionRef":"#","url":"/docs/1backend/delete-definition","content":"Delete Definition DELETE /registry-svc/definition/:id Deletes a registered definition by ID. Request​ Responses​ 204400401404500 No Content","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Create a New User","type":0,"sectionRef":"#","url":"/docs/1backend/create-user","content":"Create a New User POST /user-svc/user Allows an authenticated administrator to create a new user with specified details. Request​ Responses​ 200400401500 User created successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete Membership","type":0,"sectionRef":"#","url":"/docs/1backend/delete-membership","content":"Delete Membership DELETE /user-svc/organization/:organizationId/user/:userId Allows an organization admin to remove a user from an organization. Request​ Responses​ 200400401403404500 User added successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete Objects","type":0,"sectionRef":"#","url":"/docs/1backend/delete-objects","content":"Delete Objects POST /data-svc/objects/delete Deletes all objects matchin the provided filters. Request​ Responses​ 200400401500 Successful deletion of object","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete a Message","type":0,"sectionRef":"#","url":"/docs/1backend/delete-message","content":"Delete a Message DELETE /chat-svc/message/:messageId Delete a specific message from a chat thread by its ID Request​ Responses​ 200400401500 Message successfully deleted","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete Node","type":0,"sectionRef":"#","url":"/docs/1backend/delete-node","content":"Delete Node DELETE /registry-svc/node/:url Deletes a registered node by node URL. This endpoint is useful when a node is no longer available but it's still present in the database. Request​ Responses​ 204400401404500 No Content","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Download a File","type":0,"sectionRef":"#","url":"/docs/1backend/download-file","content":"Download a File PUT /file-svc/download Start or resume the download for a specified URL. Requires the file-svc:download:create permission. Request​ Responses​ 200400401500 Download initiated successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete a User","type":0,"sectionRef":"#","url":"/docs/1backend/delete-user","content":"Delete a User DELETE /user-svc/user/:userId Delete a user based on the user ID. Request​ Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Encrypt a Value","type":0,"sectionRef":"#","url":"/docs/1backend/encrypt-value","content":"Encrypt a Value POST /secret-svc/encrypt Encrypt a value and return the encrypted result Request​ Responses​ 200400401500 Encrypt Value Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Events","type":0,"sectionRef":"#","url":"/docs/1backend/events","content":"Events GET /chat-svc/events Events is a dummy endpoint to display documentation about the events that this service emits. Responses​ 200 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Default Model Status","type":0,"sectionRef":"#","url":"/docs/1backend/get-default-model-status","content":"Get Default Model Status GET /model-svc/default-model/status Retrieves the status of the default model. Requires the model-svc:model:view permission. Responses​ 200401500 Model status retrieved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get a Download","type":0,"sectionRef":"#","url":"/docs/1backend/get-download","content":"Get a Download GET /file-svc/download/:url Get a download by URL. Requires the file-svc:download:view permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Delete a Thread","type":0,"sectionRef":"#","url":"/docs/1backend/delete-thread","content":"Delete a Thread DELETE /chat-svc/thread/:threadId Delete a specific chat thread by its ID Request​ Responses​ 200400401500 Thread successfully deleted","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get a Model","type":0,"sectionRef":"#","url":"/docs/1backend/get-model","content":"Get a Model GET /model-svc/model/:modelId Retrieves the details of a model by its ID. the Requires model.view permission. Request​ Responses​ 200400401404500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Model Status","type":0,"sectionRef":"#","url":"/docs/1backend/get-model-status","content":"Get Model Status GET /model-svc/model/:modelId/status Retrieves the status of a model by ID. Requires the model-svc:model:view permission. Request​ Responses​ 200401500 Model status retrieved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Container Host","type":0,"sectionRef":"#","url":"/docs/1backend/get-host","content":"Get Container Host GET /container-svc/host Retrieve information about the Container host Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Has Permission","type":0,"sectionRef":"#","url":"/docs/1backend/has-permission","content":"Has Permission POST /user-svc/self/has/:permission Checks whether the caller has a specific permission. Optimized for caching — only the caller and the permission are required. To assign a permission to a user or role, use the Save Permits endpoint. This endpoint does not return 401 Unauthorized if access is denied. Instead, it always returns 200 OK with Authorized: false if the permission is missing. The response will still include the caller’s user information if not authorized. Request​ Responses​ 200400 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Check if Container Image is Pullable","type":0,"sectionRef":"#","url":"/docs/1backend/image-pullable","content":"Check if Container Image is Pullable GET /container-svc/image/:imageName/pullable Check if an image exists on in the container registry and is pullable. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Get Public Key","type":0,"sectionRef":"#","url":"/docs/1backend/get-public-key","content":"Get Public Key GET /user-svc/public-key Get the public key to verify the JWT signature. Responses​ 200400401 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Logs","type":0,"sectionRef":"#","url":"/docs/1backend/list-container-logs","content":"List Logs POST /container-svc/logs List Container logs. Requires the container-svc:log:view permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Check Security Status","type":0,"sectionRef":"#","url":"/docs/1backend/is-secure","content":"Check Security Status GET /secret-svc/is-secure Returns true if the encryption key is sufficiently secure. Responses​ 200400401500 Encrypt Value Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Definitions","type":0,"sectionRef":"#","url":"/docs/1backend/list-definitions","content":"List Definitions GET /registry-svc/definitions Retrieves a list of all definitions or filters them by specific criteria. Responses​ 200400500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Certs","type":0,"sectionRef":"#","url":"/docs/1backend/list-certs","content":"List Certs POST /proxy-svc/certs List certs that the edge proxy will use to cert requests. Request​ Responses​ 200400401500 Certs listed successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Downloads","type":0,"sectionRef":"#","url":"/docs/1backend/list-downloads","content":"List Downloads POST /file-svc/downloads List download details. Requires the file-svc:download:view permission. Responses​ 200401500 List of downloads","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Deployments","type":0,"sectionRef":"#","url":"/docs/1backend/list-deployments","content":"List Deployments POST /deploy-svc/deployments Retrieve a list of deployments. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Containers","type":0,"sectionRef":"#","url":"/docs/1backend/list-containers","content":"List Containers POST /container-svc/containers List containers. Requires the container-svc:container:view permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Service Instances","type":0,"sectionRef":"#","url":"/docs/1backend/list-instances","content":"List Service Instances GET /registry-svc/instances Retrieves a list of all instances or filters them by specific criteria (e.g., host, IP). Request​ Responses​ 200400500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Enrolls","type":0,"sectionRef":"#","url":"/docs/1backend/list-enrolls","content":"List Enrolls POST /user-svc/enrolls List enrolls. Role, user ID or contact ID must be specified. Caller can only list enrolls of roles they own. Request​ Responses​ 200401500 Enrolls listed successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Messages","type":0,"sectionRef":"#","url":"/docs/1backend/list-messages","content":"List Messages POST /chat-svc/messages Fetch messages (and associated assets) for a specific chat thread. Request​ Responses​ 200400401500 Messages and assets successfully retrieved","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Nodes","type":0,"sectionRef":"#","url":"/docs/1backend/list-nodes","content":"List Nodes POST /registry-svc/nodes Retrieve a list of nodes. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Organizations","type":0,"sectionRef":"#","url":"/docs/1backend/list-organizations","content":"List Organizations POST /user-svc/organizations Requires the user-svc:organization:view permission, that only admins have by default. Request​ Responses​ 200400401500 Organization listed successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Models","type":0,"sectionRef":"#","url":"/docs/1backend/list-models","content":"List Models POST /model-svc/models Retrieves a list of models. Requires model-svc:model:view permission. Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Permissions","type":0,"sectionRef":"#","url":"/docs/1backend/list-permissions","content":"List Permissions POST /user-svc/permissions List permissions by roles. Caller can only list permissions for roles they have. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Permits","type":0,"sectionRef":"#","url":"/docs/1backend/list-permits","content":"List Permits POST /user-svc/permits List permits. Requires the user-svc:permit:view permission, which only admins have by default. &amp;todo Users should be able to list permits referring to them. Request​ Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Prompts","type":0,"sectionRef":"#","url":"/docs/1backend/list-prompts","content":"List Prompts POST /prompt-svc/prompts List prompts that satisfy a query. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Platforms","type":0,"sectionRef":"#","url":"/docs/1backend/list-platforms","content":"List Platforms POST /model-svc/platforms Retrieves a list of AI platforms. Eg. LlamaCpp, StableDiffusion etc. Requires model-svc:platform:view permission. Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Routes","type":0,"sectionRef":"#","url":"/docs/1backend/list-routes","content":"List Routes POST /proxy-svc/routes List routes that the edge proxy will use to route requests. Request​ Responses​ 200400401500 Routes listd successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Secrets","type":0,"sectionRef":"#","url":"/docs/1backend/list-secrets","content":"List Secrets POST /secret-svc/secrets List secrets by key(s) if authorized. Request​ Responses​ 200401500 List Secret Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Threads","type":0,"sectionRef":"#","url":"/docs/1backend/list-threads","content":"List Threads POST /chat-svc/threads Fetch all chat threads associated with a specific user Request​ Responses​ 200400401500 Threads successfully retrieved","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Uploads","type":0,"sectionRef":"#","url":"/docs/1backend/list-uploads","content":"List Uploads POST /file-svc/uploads Lists uploaded files, returning only metadata about each upload. To retrieve file content, use the Serve an Uploaded File endpoint, which serves a single file per request. Note: Retrieving the contents of multiple files in a single request is not supported currently. Requires the file-svc:upload:view permission. Request​ Responses​ 200401500 List of uploads","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"List Users","type":0,"sectionRef":"#","url":"/docs/1backend/list-users","content":"List Users POST /user-svc/users Fetches a list of users with optional query filters and pagination. Requires the user-svc:user:view permission that only admins have by default. Request​ Responses​ 200400401500 List of users retrieved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Login","type":0,"sectionRef":"#","url":"/docs/1backend/login","content":"Login POST /user-svc/login Authenticates a user and returns a token. Request​ Responses​ 200400404500 Login successful","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Pause a Download","type":0,"sectionRef":"#","url":"/docs/1backend/pause-download","content":"Pause a Download PUT /file-svc/download/:url/pause Pause a download that is currently in progress. Requires the file-svc:download:edit permission. Request​ Responses​ 200400401500 Success response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Make a Model Default","type":0,"sectionRef":"#","url":"/docs/1backend/make-default","content":"Make a Model Default PUT /model-svc/model/:modelId/make-default Sets a model as the default model — when prompts are sent without a Model ID, the default model is used. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Prompt an AI","type":0,"sectionRef":"#","url":"/docs/1backend/prompt","content":"Prompt an AI POST /prompt-svc/prompt Sends a prompt and waits for a response if sync is true. If sync is false, adds the prompt to the queue and returns immediately. Prompts can be used for text-to-text, text-to-image, image-to-image, and other types of generation. If no model ID is specified, the default model will be used (see Model Svc for details). The default model may or may not support the requested generation type. Prompting Modes High-Level Parameters: Uses predefined parameters relevant to text-to-image, image-to-image, etc. This mode abstracts away the underlying engine (e.g., LLaMA, Stable Diffusion) and focuses on functionality.Engine-Specific Parameters: Uses engineParameters to directly specify an AI engine, exposing all available parameters for fine-tuned control. Permissions Required: prompt-svc:prompt:create Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Prompt Types","type":0,"sectionRef":"#","url":"/docs/1backend/prompt-types","content":"Prompt Types POST /prompt-svc/types The only purpose of this &quot;endpoint&quot; is to export types otherwise not appearing in the API docs. This endpoint otherwise does nothing. Do not depend on this endpoint, only its types. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Publish an Event","type":0,"sectionRef":"#","url":"/docs/1backend/publish-event","content":"Publish an Event POST /firehose-svc/event Publishes an event to the firehose service after authorization check Request​ Responses​ 200400401 {}","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Read Config","type":0,"sectionRef":"#","url":"/docs/1backend/read-config","content":"Read Config GET /config-svc/config Retrieves the current configuration for a specified app. If no app is specified, the default &quot;unnamed&quot; app is used. This is a public endpoint and does not require authentication. Configuration data is non-sensitive. For sensitive data, refer to the Secret Service. Configurations are used to control frontend behavior, A/B testing, feature flags, and other non-sensitive settings. Request​ Responses​ 200401500 Current configuration","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Read Self","type":0,"sectionRef":"#","url":"/docs/1backend/read-self","content":"Read Self POST /user-svc/self Retrieves user information based on the authentication token in the request header. Typically called by single-page applications during the initial page load. While some details (such as roles, slug, user ID, and active organization ID) can be extracted from the JWT, this endpoint returns additional data, including the full user object and associated organizations. ReadSelf intentionally still works after token revocation until the token expires. This is to ensure that the user is not notified of token revocation (though some information is leaked by the count token functionality @todo). Request​ Responses​ 200400500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Query Objects","type":0,"sectionRef":"#","url":"/docs/1backend/query-objects","content":"Query Objects POST /data-svc/objects Retrieves objects from a specified table based on search criteria. Requires authorization and user authentication. Use helper functions in your respective client library such as condition constructors (equal, contains, startsWith) and field selectors (field, fields, id) for easier access. Request​ Responses​ 200400401500 Successful retrieval of objects","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Refresh Token","type":0,"sectionRef":"#","url":"/docs/1backend/refresh-token","content":"Refresh Token POST /user-svc/refresh-token Refreshes an existing token, including inactive ones. The old token becomes inactive (if not already inactive), and a new, active token is issued. This allows continued verification of user roles without requiring a new login. Inactive tokens are refreshable unless explicitly revoked (no mechanism for this yet). Leaked tokens should be handled separately, via a revocation flag or deletion. Responses​ 200401500 Refresh Token successful","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Register Instance","type":0,"sectionRef":"#","url":"/docs/1backend/register-instance","content":"Register Instance PUT /registry-svc/instance Registers an instance. Idempotent. Request​ Responses​ 201400401500 Created","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Remove Instance","type":0,"sectionRef":"#","url":"/docs/1backend/remove-instance","content":"Remove Instance DELETE /registry-svc/instance/:id Removes a registered instance by ID. Request​ Responses​ 204400401404500 No Content","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Remove Prompt","type":0,"sectionRef":"#","url":"/docs/1backend/remove-prompt","content":"Remove Prompt POST /prompt-svc/remove Remove a prompt by ID. Request​ Responses​ 200400401500 {}","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Register","type":0,"sectionRef":"#","url":"/docs/1backend/register","content":"Register POST /user-svc/register Register a new user with a name, email, and password. Request​ Responses​ 200400500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Remove Secrets","type":0,"sectionRef":"#","url":"/docs/1backend/remove-secrets","content":"Remove Secrets DELETE /secret-svc/secrets Remove secrets if authorized to do so Request​ Responses​ 200401500 Remove Secret Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Reset Password","type":0,"sectionRef":"#","url":"/docs/1backend/reset-password","content":"Reset Password POST /user-svc/:userId/reset-password Allows an administrator to change a user's password. Request​ Responses​ 200400401500 Password changed successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Run a Container","type":0,"sectionRef":"#","url":"/docs/1backend/run-container","content":"Run a Container PUT /container-svc/container Runs a Docker container with the specified parameters. Requires the container-svc:container:run permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Revoke Tokens","type":0,"sectionRef":"#","url":"/docs/1backend/revoke-tokens","content":"Revoke Tokens DELETE /user-svc/tokens Revoke tokens in one of the following scenarios: For the current user.For another user (see userId field), if permitted (user-svc:token:revoke permission, typically by admins). Request​ Responses​ 200400500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Config","type":0,"sectionRef":"#","url":"/docs/1backend/save-config","content":"Save Config PUT /config-svc/config Save the provided configuration to the server Request​ Responses​ 200401500 Save Config Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Register a Definition","type":0,"sectionRef":"#","url":"/docs/1backend/save-definition","content":"Register a Definition PUT /registry-svc/definition Registers a new definition, associating an definition address with a slug acquired from the bearer token. Request​ Responses​ 201400401500 Created","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Deployment","type":0,"sectionRef":"#","url":"/docs/1backend/save-deployment","content":"Save Deployment PUT /deploy-svc/deployment Save a deployment. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Enrolls","type":0,"sectionRef":"#","url":"/docs/1backend/save-enrolls","content":"Save Enrolls PUT /user-svc/enrolls Enroll a list of users by contact or user Id to acquire a role. Works on future or current users. A user can only enroll an other user to a role if the user owns that role. A user &quot;owns&quot; a role in the following cases: A static role where the role ID is prefixed with the caller's slug.Any dynamic or static role where the caller is an admin. Examples: A user with the slug &quot;joe-doe&quot; owns roles like &quot;joe-doe:any-custom-role&quot;.A user with any slug who has the role &quot;my-service:admin&quot; owns &quot;my-service:user&quot;.A user with any slug who has the role &quot;user-svc:org:{%orgId}:admin&quot; owns &quot;user-svc:org:{%orgId}:user&quot;. Request​ Responses​ 200400401500 Enrolls saved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Message","type":0,"sectionRef":"#","url":"/docs/1backend/save-message","content":"Save Message POST /chat-svc/thread/:threadId/message Save a new message to a specific thread. Request​ Responses​ 200400401500 Message successfully added","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Membership","type":0,"sectionRef":"#","url":"/docs/1backend/save-membership","content":"Save Membership PUT /user-svc/organization/:organizationId/user/:userId Allows an organization admin to add a user to the organization. Request​ Responses​ 200400401403404500 User added successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save an Organization","type":0,"sectionRef":"#","url":"/docs/1backend/save-organization","content":"Save an Organization PUT /user-svc/organization Allows a logged-in user to save an organization. The user initiating the request will be assigned the role of admin for that organization. The initiating user will receive a dynamic role in the format user-svc:org:{organizationId}:admin, where {organizationId} is a unique identifier for the saved organization. Dynamic roles are generated based on specific user-resource associations (in this case the resource being the organization), offering more flexible permission management compared to static roles. Request​ Responses​ 200400401500 User saved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Routes","type":0,"sectionRef":"#","url":"/docs/1backend/save-routes","content":"Save Routes PUT /proxy-svc/routes Save routes that the edge proxy will use to route requests. Request​ Responses​ 200400401500 Routes saved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Permits","type":0,"sectionRef":"#","url":"/docs/1backend/save-permits","content":"Save Permits PUT /user-svc/permits Save permits. Permits give access to users with certain slugs and roles to permissions. Request​ Responses​ 200400401500 Permit saved successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Secrets","type":0,"sectionRef":"#","url":"/docs/1backend/save-secrets","content":"Save Secrets PUT /secret-svc/secrets Save secrets if authorized to do so Request​ Responses​ 200401500 Save Secret Response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save User Profile","type":0,"sectionRef":"#","url":"/docs/1backend/save-self","content":"Save User Profile PUT /user-svc/self Save user's own profile information. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save Thread","type":0,"sectionRef":"#","url":"/docs/1backend/save-thread","content":"Save Thread POST /chat-svc/thread Create or update a chat thread. Requires the chat-svc:thread:edit permission. Request​ Responses​ 200400401500 Thread successfully created","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"View Self Node","type":0,"sectionRef":"#","url":"/docs/1backend/self-node","content":"View Self Node GET /registry-svc/node/self Show the local node. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Send an Email","type":0,"sectionRef":"#","url":"/docs/1backend/send-email","content":"Send an Email POST /email-svc/email Send an email with attachments. Request​ Responses​ 200400401500 Successfully sent the email","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Save User","type":0,"sectionRef":"#","url":"/docs/1backend/save-user","content":"Save User PUT /user-svc/user/:userId Save user information based on the provided user ID. Intended for admins. Requires the user-svc:user:edit permission. For a user to edit their own profile, see saveSelf. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Serve an Uploaded File","type":0,"sectionRef":"#","url":"/docs/1backend/serve-upload","content":"Serve an Uploaded File GET /file-svc/serve/upload/:fileId Retrieves and serves a previously uploaded file using its File ID. Note: The ID and FileID fields of an upload are different. FileID is a unique identifier for the file itself.ID is a unique identifier for a specific replica of the file. Since 1Backend is a distributed system, files can be replicated across multiple nodes. This means each uploaded file may have multiple records with the same FileID but different IDs. Request​ Responses​ 200400404500 File served successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Serve a Downloaded file","type":0,"sectionRef":"#","url":"/docs/1backend/serve-download","content":"Serve a Downloaded file GET /file-svc/serve/download/:url Serves a previously downloaded file based on its URL. Request​ Responses​ 200400404500 File served successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Start the Default Model","type":0,"sectionRef":"#","url":"/docs/1backend/start-default-model","content":"Start the Default Model PUT /model-svc/default-model/start Starts The Default Model. Requires the model-svc:model:create permission. Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Serve Uploaded Image","type":0,"sectionRef":"#","url":"/docs/1backend/serve-uploaded-image","content":"Serve Uploaded Image GET /image-svc/serve/upload/:fileId Retrieves and serves a previously uploaded image file using its File ID. Request​ Responses​ 200400404500 File served successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Start a Model","type":0,"sectionRef":"#","url":"/docs/1backend/start-model","content":"Start a Model PUT /model-svc/model/:modelId/start Starts a model by ID Request​ Responses​ 200401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Stop a Container","type":0,"sectionRef":"#","url":"/docs/1backend/stop-container","content":"Stop a Container PUT /container-svc/container/stop Stops a Docker container with the specified parameters. Requires the container-svc:container:stop permission. Request​ Responses​ 200400401500 OK","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Subscribe to the Event Stream","type":0,"sectionRef":"#","url":"/docs/1backend/subscribe-to-events","content":"Subscribe to the Event Stream GET /firehose-svc/events/subscribe Establish a subscription to the firehose events and accept a real time stream of them. Responses​ 200401500 Event data","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Upsert an Instance","type":0,"sectionRef":"#","url":"/docs/1backend/upsert-instance","content":"Upsert an Instance PUT /policy-svc/instance/:instanceId Allows user to upsert a new policy instance based on a template. Request​ Responses​ 200400401500 Instance upserted successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Upload a File","type":0,"sectionRef":"#","url":"/docs/1backend/upload-file","content":"Upload a File PUT /file-svc/upload Uploads a file to the server. Currently if using the clients only one file can be uploaded at a time due to this bug https://github.com/OpenAPITools/openapi-generator/issues/11341Once that is fixed we should have an PUT /file-svc/uploads/uploadFiles (note the plural) endpoints. In reality the endpoint &quot;unofficially&quot; supports multiple files. YMMV. Requires the file-svc:upload:create permission. Request​ Responses​ 200400401500 File uploaded successfully","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Update Objects","type":0,"sectionRef":"#","url":"/docs/1backend/update-objects","content":"Update Objects POST /data-svc/objects/update Update fields of objects that match the given filters using the provided object. Any fields not included in the incoming object will remain unchanged. Request​ Responses​ 200400401500 Successful update of objects","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Subscribe to Prompt Responses by Thread","type":0,"sectionRef":"#","url":"/docs/1backend/subscribe-to-prompt-responses","content":"Subscribe to Prompt Responses by Thread GET /prompt-svc/prompts/:threadId/responses/subscribe Subscribe to prompt responses by thread via Server-Sent Events (SSE). You can subscribe to threads before they are created. The streamed strings are of type StreamChunk, see the PromptTypes endpoint for more details. Request​ Responses​ 200400401 Streaming response","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Config Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/config-svc","content":"Config Svc The Config Svc stores public, non-sensitive and end-user-facing data. This page provides a high-level overview of Config Svc. For detailed information, refer to the Secret Svc API documentation. The Config Svc is less critical than it might seem—most configuration happens internally through the Secret Svc. At the moment, it functions more like a minimal feature-flag service. Access Rules​ Read​ All configs are publicly readable even without a user account. Write​ Any logged in user can write to the config, but only to the key that matches their slug, ie. if a user's slug is jane-doe: { &quot;jane-doe&quot;: {&quot;janesConfig&quot;: 5}, &quot;someOtherKey&quot;: &quot;hi&quot; } Only the key jane-doe will be written to the Config, all other keys (such as someOtherKey) will be ignored. Related​ Secret Svc to store sensitive data like internal configuration and secrets","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Upsert Objects","type":0,"sectionRef":"#","url":"/docs/1backend/upsert-objects","content":"Upsert Objects PUT /data-svc/objects/upsert Upserts objects by ids. Request​ Responses​ 200400401500 Successful upsert of objects","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Upsert a Generic Object","type":0,"sectionRef":"#","url":"/docs/1backend/upsert-object","content":"Upsert a Generic Object PUT /data-svc/object/:objectId Creates a new dynamic object or updates an existing one based on the provided data. Requires authorization and user authentication. Request​ Responses​ 200400401500 Successful creation or update of object","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Chat Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/chat-svc","content":"Chat Svc The chat service keeps a database of threads, messages and file assets associated with them. Chat messages are the primary user interface of LLMs and other AI architectures. This page provides a high-level overview of Chat Svc. For detailed information, refer to the Chat Svc API documentation. Responsibilities​ Thread CRUDMessage CRUD","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Container Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/container-svc","content":"Container Svc The container service maintains containers on a node. It currently only supports Docker. It expects the Docker socket to be mounted. For simplicity the Container Svc is only concerned with the node it resides on. In other words, the Container Svc is not distributed, it only starts and stops containers locally. Used By​ Model Svc to launch containers running AI models.Deploy Svc to launch containers to deploy service instances. This page provides a high-level overview of Container Svc. For detailed information, refer to the Container Svc API documentation. Responsibilities​ Start and stop containers when needed - ensuring the running containers match what is expected. Dependencies​ File Svc to download asset files from.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"File Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/file-svc","content":"File Svc The File Service handles file-related operations, including downloading files from the internet (to cache them for faster access), accepting file uploads, and serving both downloaded and uploaded files. The File Svc is distributed. Downloads and uploads may reside on any node in the system, any File Svc node will be able to proxy them to you. This page provides a high-level overview of File Svc. For detailed information, refer to the File Svc API documentation. Responsibilities​ Download and cache files from the internet for faster access.Accept and store file uploads.Serve files from both cached downloads and uploaded sources. Use cases​ Internal file transfer​ Upload a file from a local node and retrieve it later using the &quot;serve upload&quot; endpoint. Application file uploads​ Enable users or services to upload files, such as profile pictures or media attachments. Component dependencies​ Download external files (e.g., AI models) via URL and provide them to system components as needed.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Deploy Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/deploy-svc","content":"Deploy Svc The deploy service is responsible of launching containers on whatever infrastructure the 1Backend is running on (eg. Docker Svc) and registering them into the Registry Svc. This page provides a high-level overview of Deploy Svc. For detailed information, refer to the Deploy Svc API documentation. Warning​ Deployment capabilities are unfinished. This section is only for contributors. Deploy your services manually for now. Types of services​ On 1Backend, services generally fall into the following categories: Services deployed by the Deploy Svc: These can include services built with the 1Backend SDK or standard containers (e.g., NGINX) that are not 1Backend-specific.Services built with the 1Backend SDK but deployed through other methods; for example, using Docker Compose or Kubernetes. These services self-register into the Registry Svc. Entities​ Deployment​ id: depl_dbOdi5eLQK definitionId: def_deBXZMpxrQ name: user-service-v2 description: Handles user service requests replicas: 3 strategy: type: RollingUpdate maxUnavailable: 1 maxSurge: 2 resources: cpu: &quot;500m&quot; memory: &quot;256Mi&quot; vram: &quot;24GB&quot; autoScaling: minReplicas: 2 maxReplicas: 10 cpuThreshold: 80 targetRegions: - cluster: us-west1 zone: us-west1-b - cluster: local-docker status: OK details: Deployment is in progress envars: ENVIRONMENT: production LOG_LEVEL: debug FEATURE_FLAG_X: &quot;true&quot; Dependencies​ Container Svc to start containers of servicesRegistry Svc to start containers of services","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Policy Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/policy-svc","content":"Policy Svc The policy service provides features such as rate limiting of endpoint calls by user ip, user id, organization id and more. This page provides a high-level overview of Policy Svc. For detailed information, refer to the Policy Svc API documentation. Responsibilities​ Provide tools for service writers to prevent adversarial users from causing service degradation How It Works​ The Policy Svc requires you to explicitly call the /policy-svc/check endpoint in every service endpoint you are building. There is no magic or framework feature involved. Usage​ The policy service has two endpoint: You can create policy instances with /policy-svc/upsert-instance - use this to define rate limits, block IPs etc.A /policy-svc/check endpoint that you should call for every request in your endpoint you want to rate limit. While the documentation should be thorough, it might be not be the easiest to understand at first glance due to the presence of *Parameters fields which are specific to Policy Templates. Terms​ Policy Templates​ Policy Templates are hardcoded features of the Policy Svc: Rate Limit​ Rate Limit (templateId: rate-limit) provides rate limiting various entities and scopes, see the rateLimitParameters in the api doc). Blocklist​ Blocklist provides blocking of access by ip addresses, see the blocklistParameters in the api doc). Policy Instance​ A policy instance is a specific application of a policy template to certain data like endpoints, user ids, ip addresses etc. Examples​ Rate Limit​ The following /policy-svc/upsert-instance payload rate limits calls to the register endpoint by caller IP: maximum 5 calls are permitted per IP per day: { &quot;instance&quot;: { &quot;endpoint&quot;: &quot;/user-svc/register&quot;, &quot;id&quot;: &quot;insta_dBZRCej3fo&quot;, &quot;rateLimitParameters&quot;: { &quot;entity&quot;: &quot;ip&quot;, &quot;maxRequests&quot;: 5, &quot;scope&quot;: &quot;endpoint&quot;, &quot;timeWindow&quot;: &quot;1d&quot; }, &quot;templateId&quot;: &quot;rate-limit&quot; } } Block by IP​ The following /policy-svc/upsert-instance payload blocks access to the register endpoint by ip address. { &quot;instance&quot;: { &quot;endpoint&quot;: &quot;/user-svc/register&quot;, &quot;id&quot;: &quot;insta_dBZRCej3fo&quot;, &quot;blocklistParameters&quot;: { &quot;blockedIPs&quot;: [&quot;8.8.8.8&quot;] }, &quot;templateId&quot;: &quot;rate-limit&quot; } } ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Model Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/model-svc","content":"Model Svc The model service can start, stop AI models across multiple runtimes (eg. Docker) and maintains a database of available models on the platform. This page provides a high-level overview of Model Svc. For detailed information, refer to the Model Svc API documentation. Responsibilities​ Start and stop modelsMaintain a database of models and other related information such as the default model Dependencies​ Container Svc to start containerized AI models (eg. Llama, Stabel Diffusion etc.) Current Limitations​ Stop model endpoint is missing","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Prompt Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/prompt-svc","content":"Prompt Svc The prompt service provides an easy to use interface to prompt LLMs and use AI models. Aims to serve humans and machines alike with its resilient queue based architecture. This page provides a high-level overview of Prompt Svc. For detailed information, refer to the Prompt Svc API documentation. Responsibilities​ The prompt service: Accepts promptsMaintains a list of promptsProcesses prompts as soon as it's able toStreams prompt answersHandles retries of prompts that errored with an exponential backoff It's able to stream back LLM responses, or it can respond syncronously if that's what the caller wants, for details see the Add Prompt (/prompt-svc/prompt) Endpoint. Dependencies​ Chat Svc to save prompt responses to chat threads and messagesModel Svc to get the address of the running AI models, see their status etc. Current limitations​ There are planned improvements for this service: It should manage models: start needed ones and stop unneeded ones based on the volume of prompts in the backlog","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Registry Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/registry-svc","content":"Registry Svc The registry service is designed to maintain a database of service definitions, service instances and nodes. This page provides a high-level overview of Registry Svc. For detailed information, refer to the Registry Svc API documentation. Entities​ Definition​ A Definition or service definition consists of the following things: An IDA container image to run and some additional information like the internal port exposed etc.A set of endpoint definitions (OpenAPI etc.)The URL of different clients (JS, Go etc.) A Definition is an abstract concept that can not be called. For a callable entity look at Instances. Definitions are basically things you can deploy as an instance with a deployment. Container based definition​ id: test-a image: name: hashicorp/http-echo port: 8080 hostPort: 8887 Notes​ HostPorts are a temporary requirement until support for dynamic port assignment lands. Source code based definition​ id: test-b repository: url: https://github.com/1backend/1backend.git containerFile: server/docker/Dockerfile hostPort: 9998 Instance​ A Instance or a service instance is an actual running, callable instance of a Definition. A Instance consists of the following things: Address information that can be used to internally address the Instance.A Deployment ID. Deployment​ Definitions become instances through the Deployment entity of the Deploy Service. Node​ A Node is a physical or virtual machine that runs a 1Backend server. Maintaining a list of nodes is important so the daemon can efficiently distribute workload across the nodes. It's the basis for all distributed features. This is how a well configured node should look like: $ oo nodes lis NODE ID URL LAST HEARTBEAT myNodeId http://myNetworkInternalHost:11337 8s ago For well configured nodes, the following must be present Each node should have a unique URL (eg. 127.0.0.1 for all nodes is not unique...)Each node URL should be addressable by every node including themselvesA node ID should be defined to avoid the more error prone ID generation Here is how a suboptimally configured node looks like: $ oo nodes lis NODE ID URL LAST HEARTBEAT node_eIfnt9CGJV http://127.0.0.1:11337 8s ago For single node setups that can work, but not if you plan to use distributed features. To configure the nodes, please see the OB_SELF_URL and OB_NODE_ID envars here How It Works​ The registry is needed when you want to call services not included in the 1Backend server. You can think of the daemon as the standard library and services in the registry as third party libraries. When you want to call a service, you can ask the registry to provide you with a list of instance addresses for a service by service slug. Then you can use any of those instance addresses to make a call. Things like load balancing should be done on the client side at the moment, the damon does not provide a Proxy Svc yet.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Proxy Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/proxy-svc","content":"Proxy Svc The Proxy Service in 1Backend handles various forms of proxying: Service proxying: Proxies requests to custom services registered in the registry.Edge proxying: When OB_EDGE_PROXY is set to true and the appropriate Routes are configured, the proxy service can handle HTTPS requests and perform TLS termination. This page provides a high-level overview of Proxy Svc. For detailed information, refer to the Proxy Svc API documentation. Service proxying​ When you send a request to 1Backend, for example: curl 127.0.0.1:11337/user-svc/login ... One of two things will happen: If the request matches a built-in service, it is routed there.Otherwise, the registry is consulted. If a custom service exists with a slug matching the first path segment (e.g., user-svc), the request is routed to it. Client Request: curl 127.0.0.1:11337/user-svc/login | v +-----------------------------------------+ | Is &quot;user-svc&quot; a built-in service? | +-----------------------------------------+ | | Yes No | | v v +----------------------+ +-----------------------+ | Route directly to | | Proxy Svc | | built-in service | +-----------------------+ +----------------------+ | v +-------------------------------+ | Look up &quot;user-svc&quot; in registry| +-------------------------------+ | v +--------------------------+ | Proxy to target service | +--------------------------+ Edge proxying​ When edge proxying is enabled, 1Backend also listens on ports 80 (HTTP) and 443 (HTTPS). It can automatically manage HTTPS certificates (requesting and renewing them as needed) for your configured domains. $ oo routes list ROUTE ID TARGET api.singulatron.com http://1backend:11337 singulatron.com http://frontend:8080 +----------------------+ | Browser / Client | | (requests HTTPS) | +----------+-----------+ | Request to domain (e.g. https://singulatron.com) | v +------------------------+ | Port 443 (TLS) | | TLS termination by | | Proxy Svc (edge) | +------------------------+ | Match domain in Routes | v +------------------------------+ | Route found: | | singulatron.com | | → http://frontend:8080 | +------------------------------+ | v +---------------------+ | Target container | | (e.g. frontend) | +---------------------+ ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Secret Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/secret-svc","content":"Secret Svc The Secret Svc stores sensitive or internal (non-end-user-facing) configuration. Aims to store all configuration not required at bootstrap, both for internal and external services. This page provides a high-level overview of Secret Svc. For detailed information, refer to the Secret Svc API documentation. Access rules​ Read​ Any logged in user who is amongst a Secret's Readers can read a secret. Write​ Create​ Any logged in user can create a secret. Non-admin users can only create secrets with the key prefixed by their slug, ie: deploy-svc/EXAMPLE-KEY vs non-prefixed keys such as EMAIL_API_KEY Non-prefixed keys like EMAIL_API_KEY can only be created by admin users. This prefix rule serves two purposes: It is clear which secret keys are &quot;static&quot; and originating from admin usersIt can prevent issues where a user claims a key knowing that it might be used later and overwritten/populated by an admin with sensitive information Update​ After a key is created further write access is governed by the Writers block. Entities​ Secret​ id: &quot;secr_eG8IvKwB0A&quot; key: &quot;MY_API_KEY&quot; value: &quot;nNl4X9+@95Z&quot; # Slugs of services and users who can read the secret readers: - &quot;alice&quot; - &quot;bob&quot; # Slugs of services and users who can modify the secret writers: - &quot;alice&quot; - &quot;bob&quot; # Slugs of services and users who can delete the secret deleters: - &quot;service-admin&quot; # Slugs of services and users who can change the &quot;readers&quot; list canChangeReaders: - &quot;alice&quot; # Slugs of services and users who can change the &quot;writers&quot; list canChangeWriters: - &quot;alice&quot; # Slugs of services and users who can change the &quot;deleters&quot; list canChangeDeleters: - &quot;alice&quot; Design choices​ The Secret Svc, like most things in 1Backend, is designed to be simple to reason about. Instead of the 1Backend injecting environment variables into service containers when they are deployed, the services are left to their own devices to read secrets from the Secret Svc through normal service calls, using their credentials. This approach also works for services that you deploy manually (e.g., Kubernetes, Docker Compose) rather than through 1Backend. Encryption at rest and transit​ All data is encrypted using the encryption key provided by the envar OB_ENCRYPTION_KEY (see Todo section). The server encrypts the secret values before saving them to disk/DB. The secret values are transmitted to readers unencrypted. Tips​ Encrypt​ The encrypt command helps you create encrypted YAML files that can be safely stored in source control and integrated into Infrastructure-as-Code (IaC) or GitOps workflows. This ensures sensitive data is protected while enabling automated deployment processes. $ oo secret encrypt example-key example-value id: &quot;secr_eR6LbYOBK2&quot; key: &quot;example-key&quot; value: &quot;62bQMQf5wPMrAsJ7+bcZpKBMtA7Ap7DF6xZaioq9jU0=&quot; encrypted: true checksum: &quot;45a3b25f&quot; checksumAlgorithm: &quot;CRC32&quot; Save the output to a file and, in your continuous delivery pipeline, apply it: $ oo secret save my-api-key.yaml Checksum​ Checksums are optional and serve to verify the integrity of encrypted values. When an already encrypted value is saved in the Secret Svc, the service decodes it and uses the checksum to ensure the value remains intact. Is Secure​ After setting up your daemon it's a good idea to check if the Secret Svc is secure: $ oo secret is-secure Service is secure. This will return successfully if the encryption key has been changed from the default value and all necessary setup steps have been completed.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Data Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/data-svc","content":"Data Svc The Data Service (Data Svc) is designed to facilitate backendless applications, allowing data to be saved and queried directly from the frontend, similar to Firebase. This page provides a high-level overview of Data Svc. For detailed information, refer to the Data Svc API documentation. Purpose​ Data Svc serves as a lightweight database abstraction designed for rapid prototyping. It allows direct reading, writing, and deletion from the frontend, eliminating the need for basic CRUD microservices that merely handle routine database operations. Data types​ Currently, Data Svc supports only untyped, dynamic, and schemaless entries known as Objects. Objects​ Data model​ Multiple tenants (users or services) write to shared tables. Access is governed by the permission model outlined below. Permission model​ The Data Svc Object permission model is designed with two primary goals: Simplicity – Easy to understand and implementFlexibility – Versatile while maintaining simplicity To illustrate the model, consider the following example entry: table: &quot;pet&quot; id: &quot;pet_67890&quot; data: yourCustomKey1: &quot;yourCustomValue1&quot; yourCustomKey2: 42 readers: - &quot;usr_12345&quot; - &quot;org_67890&quot; writers: - &quot;org_67890&quot; deleters: - &quot;usr_12345&quot; authors: - &quot;usr_99999&quot; - &quot;org_99999&quot; Readers​ The readers field defines which users, organizations, or roles have permission to view an entry. Users and organizations outside of your own can be permited access.This field can be set by the author or writers to include user IDs, organization IDs, or roles they themselves do not belong to. Authors​ The authors field identifies the original creators of an entry. Unlike readers, writers, and deleters, which are user-defined, this field is system-assigned. It can only include the author's user ID, organization IDs they belong to, or roles they hold. This ensures it cannot be altered or spoofed, helping to prevent spam. In multi-tenant applications, spam can occur because anyone can &quot;offer&quot; a record to be read by another user or organization they are not part of. This can be problematic—for example, in a chat application where strangers could send unsolicited messages simply by knowing a company ID.The authors field helps prevent such abuse limiting the list to resources the author has. Writers​ The writers field specifies which users, organizations, or roles have permission to modify an entry. This field can be set by the author or existing writers to include user IDs, organization IDs, or roles they themselves do not belong to. Deleters​ The deleters field defines which users, organizations, or roles are authorized to delete an entry. This field can be set by the author or existing writers to include user IDs, organization IDs, or roles they themselves do not belong to. Conventions​ Table name and object ID​ Each object ID must be prefixed with the table name. Whenever possible, use singular table names. table: &quot;pet&quot; id: &quot;pet_67890&quot; _self​ You can specify the reserved string _self in the readers, writers or deleters lists. It will be extrapolated to your user ID. Querying​ Data Svc allows querying objects with flexible filtering, sorting, and pagination options. Ordering by descending value​ Request { &quot;table&quot;: &quot;pet&quot;, &quot;query&quot;: { &quot;orderBys&quot;: [ { &quot;field&quot;: &quot;age&quot;, &quot;desc&quot;: true, &quot;sortingType&quot;: &quot;numeric&quot; } ] } } You might wonder what sorting type is. It is essentially a clutch for some systems like PostgreSQL, where the Data Svc and its ORM stores the dynamic fields of Objects in a JSONB field. Unfortunately ordering on JSONB fields defaults to string sorting. The sortingType field helps the system force the correct ordering. For possible ordering values, see the queryObjects endpoint API Response: { &quot;objects&quot;: [ { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_19&quot;, &quot;data&quot;: { &quot;age&quot;: 19 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_18&quot;, &quot;data&quot;: { &quot;age&quot;: 18 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_17&quot;, &quot;data&quot;: { &quot;age&quot;: 17 } } ] } Ordering by ascending value​ { &quot;table&quot;: &quot;pet&quot;, &quot;query&quot;: { &quot;orderBys&quot;: [ { &quot;field&quot;: &quot;age&quot;, &quot;sortingType&quot;: &quot;numeric&quot; } ] } } Response: { &quot;objects&quot;: [ { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_0&quot;, &quot;data&quot;: { &quot;age&quot;: 0 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_1&quot;, &quot;data&quot;: { &quot;age&quot;: 1 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_2&quot;, &quot;data&quot;: { &quot;age&quot;: 2 } } ] } Limiting results​ { &quot;table&quot;: &quot;pet&quot;, &quot;query&quot;: { &quot;orderBys&quot;: [ { &quot;field&quot;: &quot;age&quot;, &quot;sortingType&quot;: &quot;numeric&quot; } ], &quot;limit&quot;: 5 } } Response: { &quot;objects&quot;: [ { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_0&quot;, &quot;data&quot;: { &quot;age&quot;: 0 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_1&quot;, &quot;data&quot;: { &quot;age&quot;: 1 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_2&quot;, &quot;data&quot;: { &quot;age&quot;: 2 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_3&quot;, &quot;data&quot;: { &quot;age&quot;: 3 } }, { &quot;table&quot;: &quot;pet&quot;, &quot;id&quot;: &quot;pet_4&quot;, &quot;data&quot;: { &quot;age&quot;: 4 } } ] } Paginating with after​ Request: { &quot;table&quot;: &quot;pet&quot;, &quot;query&quot;: { &quot;orderBys&quot;: [ { &quot;field&quot;: &quot;age&quot;, &quot;sortingType&quot;: &quot;numeric&quot; } ], &quot;limit&quot;: 5, &quot;jsonAfter&quot;: &quot;[4]&quot; } } The after field is named jsonAfter and is a string-marshalled array to address limitations in Swaggo. Specifically, Swaggo converts []interface to []map[string]interface, and there is no way to define a type that resolves to an any/interface during the go -&gt; openapi -&gt; go generation process. Therefore, jsonAfter is a JSON-encoded string representing an array, e.g., [42]. Response: { &quot;objects&quot;: [ { &quot;table:&quot; &quot;pet&quot;, &quot;id&quot;: &quot;pet_5&quot;, &quot;data&quot;: { &quot;age&quot;: 5 } }, { &quot;table:&quot; &quot;pet&quot;, &quot;id&quot;: &quot;pet_6&quot;, &quot;data&quot;: { &quot;age&quot;: 6 } }, { &quot;table:&quot; &quot;pet&quot;, &quot;id&quot;: &quot;pet_7&quot;, &quot;data&quot;: { &quot;age&quot;: 7 } }, { &quot;table:&quot; &quot;pet&quot;, &quot;id&quot;: &quot;pet_8&quot;, &quot;data&quot;: { &quot;age&quot;: 8 } }, { &quot;table:&quot; &quot;pet&quot;, &quot;id&quot;: &quot;pet_9&quot;, &quot;data&quot;: { &quot;age&quot;: 9 } } ] } Paginating with after in descending order​ Request: { &quot;table&quot;: &quot;pet&quot;, &quot;query&quot;: { &quot;orderBys&quot;: [ { &quot;field&quot;: &quot;age&quot;, &quot;desc&quot;: true, &quot;sortingType&quot;: &quot;numeric&quot; } ], &quot;limit&quot;: 5, &quot;jsonAfter&quot;: &quot;[15]&quot; } } Response: { &quot;objects&quot;: [ { &quot;id&quot;: &quot;pet_14&quot;, &quot;data&quot;: { &quot;age&quot;: 14 } }, { &quot;id&quot;: &quot;pet_13&quot;, &quot;data&quot;: { &quot;age&quot;: 13 } }, { &quot;id&quot;: &quot;pet_12&quot;, &quot;data&quot;: { &quot;age&quot;: 12 } }, { &quot;id&quot;: &quot;pet_11&quot;, &quot;data&quot;: { &quot;age&quot;: 11 } }, { &quot;id&quot;: &quot;pet_10&quot;, &quot;data&quot;: { &quot;age&quot;: 10 } } ] } ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"User Svc","type":0,"sectionRef":"#","url":"/docs/built-in-services/user-svc","content":"User Svc The user service is at the heart of 1Backend, managing users, tokens, organizations, permissions and more. Each service and human on an 1Backend network has an account in the User Svc. This page provides a high-level overview of User Svc. For detailed information, refer to the User Svc API documentation. User Svc supports multitenancy: while users are shared globally, tokens, organizations, permits, enrollments, and memberships are isolated by an &quot;app&quot; field. This approach allows a single 1Backend instance to securely support multiple web applications. Note: Not all services included with 1Backend may support multitenancy. Please refer to the documentation for details and look for the tag multitenant. Glossary​ Token: A JWT (JSON Web Token) issued and signed by the User Svc, used to authenticate both human and service accounts. Role: A simple string identifier like user-svc:user or user-svc:org:{orgId}:admin that represents a specific capability or access level. Roles are embedded in tokens. Enroll: (Enrollment) A mechanism to assign roles to users—both current and future. Enrolls allow roles to be claimed later, once the user joins or logs in. Permission: A string such as petstore-svc:read, typically mapping to an API action or endpoint. Roles can bundle multiple permissions. Permit: A mechanism for assigning permissions to users or roles. Permits define who can access what by connecting users or roles with specific permissions. Organization: A way for users to freely associate with each other. Anyone can create organizations and grant membership to others to their organization. Membership: A formal record that links a user to an organization. Memberships determine which organizations a user belongs to and enable organization-scoped roles to take effect. Overview​ The most important thing about the User Svc is that service (machine) and user (human) accounts look and function the same. Every service you write needs to register at startup, or log in with the credentials it saves and manages if it's already registered. Just like a human. A service account is not an admin account, it's a simple user level account. You might wonder how service-to-service calls work then. Service to service calls​ Most endpoints on 1Backend can only be called by administrators by default. Let's take prompting. If you want to let your users prompt AIs you might write a wrapper service called User Prompter Svc with the slug user-prompter-svc. If we look at the Add Prompt endpoint API docs, we can see that it mentions Requires the `prompt-svc:prompt:create` permission. To enable your service to call the Add Prompt endpoint, we need to create a permit with your service slug and the permission mentioned above: id: &quot;user-prompter-permit&quot; permissionId: &quot;prompt-svc:prompt:create&quot; slugs: - &quot;user-prompter-svc&quot; You can apply these permits with an administrator account in your CI workflow with the oo CLI: oo permit save user-prompter-permit.yaml Auth patterns​ Role-based access​ Role-Only Checks: Authorize users based solely on their assigned roles. This is the simplest method—no need to check individual permissions. Permission-based access​ API Permission Check: Use the Has Permission endpoint with the user's authentication headers and a permission ID to verify access dynamically. This endpoint is designed to be easy to cache (it has no other params apart from the caller header and a permission). Permission-based checks offer more nuanced control than simple role-only checks—permits can grant specific permissions to slugs, roles and more. If you are looking at restricting access to endpoints in other ways, you might be interested in: Policy Svc. Tokens​ The User Svc produces a JWT (JSON Web Token) upon /user-svc/login in the token.token field (see the response documentation). You can either use this token as a proper JWT - parse it and inspect the contents, or you can just use the token to read the user account that belongs to the token with the /user-svc/self endpoint. Verifying a token​ The /user-svc/public-key will return you the public key of the User Svc which then you can use that to verify the token. Use the JWT libraries that are available in your programming language to do that, or use the Singularon SDK if your language is supported. Automatic token refresh​ 1Backend tokens are valid for a limited time (see OB_TOKEN_EXPIRATION). Once a token expires, 1Backend can either automatically refresh it (this is the default behaviour) or reject it based on configuration (see OB_TOKEN_AUTO_REFRESH_OFF). If automatic token refresh is disabled, clients are responsible for detecting expiration and refreshing the token themselves. If automatic refresh is enabled, expired tokens can still be reused indefinitely. Behind the scenes, 1Backend maps old tokens to their most recent valid version. Example flow​ To understand how automatic token refresh works in practice, consider the following scenario: A user acquires a token.The token is valid for X minutes.After expiration, Service A receives a request with the old token.Service A then has two options: Call the User Svc RefreshToken endpoint on every request to get a new token — which undermines the stateless nature of JWTs.Cache the refreshed token and continue accepting the expired one, internally mapping it to the latest valid token without calling 1Backend. When the refreshed token expires, this process repeats. Token Pruning​ You might wonder: if an old token keeps getting refreshed indefinitely, does that mean a new token is minted every OB_TOKEN_EXPIRATION interval — and do they pile up forever? While a new token is issued on each refresh, the system keeps track of which tokens are actively being refreshed and discards the rest. At any given time, a maximum of three tokens per device (see the device field in the token) are retained: The currently active tokenThe two most recently refreshed tokens (kept as a buffer to handle clock drift or retries) All other older tokens are pruned to avoid unbounded growth. Token structure​ The structure of the JWT is the following: # User Id oui: usr_dC4K75Cbp6 # Slug osl: test-user-slug-0 # Roles oro: - user-svc:user - user-svc:org:{org_dC4K7NNDCG}:user The field names are kept short to save space, so perhaps the Go definition is also educational: type Claims struct { UserId string `json:&quot;oui&quot;` // `oui`: 1backend user ids Slug string `json:&quot;osl&quot;` // `osl`: 1backend slug Roles []string `json:&quot;oro&quot;` // `oro`: 1backend roles jwt.RegisteredClaims } Roles​ Roles are simply strings. They are not a database record, they don't have an ID, name etc. They are simple strings, such as user-svc:admin. A user token produced upon login contains all the roles a user has. Efficiency Tip: JWT tokens are sent with every request. Keeping the number of roles minimal improves performance. When checking if a user is authorized, there are a few common patterns to choose from: Roles without permissions​ Roles are powerful, even without specific permissions attached. One common use case is managing product subscriptions. Suppose you launch a new product called Funny Cats Newsletter with two subscription tiers: Pro and Ultra. You could create a service with the slug funny-cats-newsletter-svc and define custom static roles for each tier: funny-cats-newsletter-svc:pro funny-cats-newsletter-svc:ultra By checking if these roles exist in a user's token, you can authorize access to product-specific features. These roles can be created dynamically by calling the Create Role endpoint. Roles containing dynamic data​ You are free to make up your own roles which might even have dynamic data, just like the User Svc did with the organization ids. Example: user-svc:org:{org_dBZRCej3fo}:admin user-svc:org:{org_dBZRCej3fo}:user By convention these dynamic values are enclosed in . In this example, roles are assigned per organization. For more details, see the Organizations section. Owning roles vs. having roles​ In many endpoints such SaveEnrolls, the topic of &quot;role ownership&quot; comes up. The basic problem is simple: just because someone has a role, it doesn't mean they can also bestow that role upon other users. In simple terms, if an admin makes someone a user, that user should not be able to make others users, as that is the privilege of the admins. A user &quot;owns&quot; a role in the following cases: The role is prefixed with the caller's slug. For example, a user with the slug joe-doe owns roles like joe-doe:any-custom-role.User &quot;owns&quot; all roles that share a prefix if they hold the corresponding :admin role. For example, having user-svc:org:{org_id}:admin means the user owns roles like user-svc:org:{org_id}:user and user-svc:org:{org_id}:viewer. By enforcing role ownership rules, the system ensures that roles are only assigned by authorized users, preventing privilege escalation and maintaining security within the organization. Conventions​ Each role created must by prefixed by the slug of the account that created it. Said account becomes the owner of the role and only that account can edit the role. Organizations​ In the dynamic roles section we already talked about organizations, lets elaborate on them here a bit. id: &quot;org_eZqC0BbdG2&quot; name: &quot;Acme Corporation&quot; # Full name of the organization slug: &quot;acme-corporation&quot; # URL-friendly unique identifier for the organization createdAt: &quot;2025-01-15T12:00:00Z&quot; # Example ISO 8601 timestamp Access rules​ Create​ Any logged in user can create an organization, provided the Organization slug is not taken yet. The creator becomes the first admin of the organization, acquiring the role of user-svc:org:{orgId}:admin role. Membership​ Admins can assign other users member (user-svc:org:{orgId}:user) or admin roles (user-svc:org:{orgId}:admin) for the organizations they administer. Use cases​ Organizations let users to freely associate with each other and create groups. Think about Discord servers, Slack workspaces, Github organizations etc. Permissions​ Conventions​ Each permission created must by prefixed by the slug of the account that created it. Said account becomes the owner of the permission and only that account can add the permission to a role. Once you (your service) own a permission (by creating it, and it being prefixed by your account slug), you can add it to any role, not just roles owned by you. Example; let's say your service is petstore-svc. 1Backend prefers fine-grained access control, so you are free to define your own permissions, such as petstore-svc:read or petstore-svc:pet:read. Services with multiple nodes​ You might now wonder what happens when a service has multiple instances/nodes. Won't their user accounts &quot;clash&quot; in the User Svc? The answer to this is that from the User Svc point of view, each node/instance of a service is the same account. This is possible because the platform is designed with services having a &quot;Shared Database Access&quot;. Let's say you have a Cassandra network that spans multiple Availability Zones/Regions. Your nodes will also span multiple AZs/Regions and each instance of them will log in as X Svc.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Contribute to the Clients","type":0,"sectionRef":"#","url":"/docs/contributing/contributing-to-the-clients","content":"Contribute to the Clients TypeScript/JavaScript Clients​ Without some scripting making sweeping changes in the clients would be hard because of how they depend on each other: js/types (@singulatron/types) is a dependency of js/client (@singulatron/client). To fix this a tiny script link_local.sh was introduced. Your local workflow when editing the @singulatron/types should be is to issue the bash link_local.sh in the clients/js folder. The script links up and builds the packages in the correct order for local testing. Publishing​ Just bump the version number in the package.jsons and the clients will be automatically published when merged to main.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Contribute to the Docs","type":0,"sectionRef":"#","url":"/docs/contributing/contributing-to-the-docs","content":"Contribute to the Docs Step into the docs-source folder from the repo root and run npm run start to see the Documentation section in live reload mode. However, the API section won't refresh automatically. To change the API, you must edit the Go endpoints and run bash build.sh in the docs-source folder. You can run bash build.sh while npm run start is active for a relatively quick feedback loop.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Welcome to 1Backend","type":0,"sectionRef":"#","url":"/docs/intro","content":"Welcome to 1Backend 1Backend transforms your servers into a powerful development environment. It can run AI models, containers, and microservices. Whether you're deploying AI or building microservices, 1Backend is your one-stop shop for creating and managing applications, all while keeping full control over your infrastructure and data. Running the server​ The first step is to run the daemon. For details about that, see Running the Server. Built-in services​ For a quick overview about what the system is capable, read through the Built-in Service Docs. Building your services​ To build and run your own services on 1Backend, see Your First Service Privacy notice​ Privacy is of prime importance to us. To learn more about the privcy aspects of this software, visit the Privacy Notice page.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Privacy Notice","type":0,"sectionRef":"#","url":"/docs/privacy-notice","content":"Privacy Notice This document details the privacy considerations of 1Backend. Overview​ By running AIs locally/on-premise with 1Backend, neither the questions nor the answers leave your computer/premises. There are a few dependencies that are so huge that they are not bundled with 1Backend and must be downloaded at the start of the application: Things 1Backend downloads​ Model Files​ The model weights themselves are downloaded from https://huggingface.co. Docker Containers​ Docker containers are a form of lightweight virtualization technology that enables 1Backend to run a wide range of AI architectures. Things 1Backend uploads​ None.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Command line basics","type":0,"sectionRef":"#","url":"/docs/command-line/basics","content":"Command line basics CLI installation​ At the moment you need Go to install the 1Backend CLI: go install github.com/1backend/1backend/cli/oo@latest CLI usage​ Assuming the daemon is running already (see this section about that), you can interact with it through the CLI. Let's add the local environment first: $ oo env add local http://127.0.0.1:11337 $ oo env ls SELECTED NAME URL DESCRIPTION * local http://127.0.0.1:11337 After this you you need to log in: $ oo login 1backend Enter password: $ oo whoami slug: 1backend id: usr_eH9mXKgmb0 roles: - user-svc:admin Let's make a GET call: $ oo get /config-svc/config {&quot;config&quot;:{&quot;app&quot;:&quot;unnamed&quot;,&quot;data&quot;:{&quot;configSvc&quot;:{&quot;directory&quot;:&quot;/root&quot;},&quot;downloadSvc&quot;:{&quot;downloadFolder&quot;:&quot;/root/downloads&quot;},&quot;modelSvc&quot;:{&quot;currentModelId&quot;:&quot;huggingface/TheBloke/mistral-7b-instruct-v0.2.Q3_K_S.gguf&quot;}}}} Or a POST call: $ oo post /user-svc/users { &quot;users&quot;: [ { &quot;id&quot;: &quot;usr_e9WSYwjRuL&quot;, &quot;createdAt&quot;: &quot;2024-12-06T20:51:38.062985Z&quot;, &quot;updatedAt&quot;: &quot;2024-12-06T20:51:38.062985Z&quot;, &quot;name&quot;: &quot;Proxy Service&quot;, &quot;slug&quot;: &quot;proxy-svc&quot;, &quot;contacts&quot;: [ { &quot;createdAt&quot;: &quot;0001-01-01T00:00:00Z&quot;, &quot;updatedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; } ] }, ... Or a POST call with some request body parameters: $ oo post /secret-svc/encrypt --value=hey { &quot;value&quot;: &quot;UsoGq6VCa0+89pzIPhgU49kgoL0p/3jc90IsOR/8ldk=&quot; } Here we should talk a bit about how CLI flags get mapped to request bodies. CLI flag to request body mapping​ When doing POST, PUT and DELETE queries, CLI flags can be turned into multilevel JSON request bodies, such as this: $ oo post /secret-svc/encrypt --value=hey Is roughly equivalent to the pseudocurl curl -XPOST -H &quot;Auth...&quot; $ADDR/secret-svc/encrypt -d '{&quot;value&quot;: &quot;hey&quot;}' Similarly, dot . and dash - delimiters get turned into a multidimensional JSON: $ oo post /secret-svc/encrypt --value-text=hey # turns into { &quot;value&quot;: { &quot;text&quot;: &quot;hey&quot; } } $ oo post /secret-svc/encrypt --value.text=hey # turns into { &quot;value&quot;: { &quot;text&quot;: &quot;hey&quot; } } $ oo post /secret-svc/encrypt --valueText=hey # turns into { &quot;valueText&quot;: &quot;hey&quot; } ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Supported LLMs","type":0,"sectionRef":"#","url":"/docs/platform-capabilities/supported-llms","content":"Supported LLMs LLaMA 🦙 LLaMA 2 🦙🦙 LLaMA 3 🦙🦙🦙 Mistral 7B Mixtral MoE DBRX Falcon Chinese LLaMA / Alpaca and Chinese LLaMA-2 / Alpaca-2 Vigogne (French) BERT Koala Baichuan 1 &amp; 2 + derivations Aquila 1 &amp; 2 Starcoder models Refact MPT Bloom Yi models StableLM models Deepseek models Qwen models PLaMo-13B Phi models GPT-2 Orion 14B InternLM2 CodeShell Gemma Mamba Grok-1 Xverse Command-R models SEA-LION GritLM-7B + GritLM-8x7B OLMo GPT-NeoX + Pythia ChatGLM3-6b + ChatGLM4-9b","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Running the 1Backend server with Docker Compose and prebuilt images","type":0,"sectionRef":"#","url":"/docs/running-the-server/docker-compose","content":"Running the 1Backend server with Docker Compose and prebuilt images This deployment method is one step above local development in terms of sophistication. It’s suitable for a development server or simple production environments. This snippet will give you a quick idea about how to deploy the frontend and backend containers so they play nicely together: version: &quot;3.8&quot; volumes: 1backend-data: name: 1backend-data driver: local services: 1backend-ui: image: crufter/1backend-ui:latest ports: - &quot;3901:80&quot; environment: # `BACKEND_ADDRESS` must be reachable from the browser. # This is the API the browser will communicate with, not an internal address. - BACKEND_ADDRESS=http://127.0.0.1:11337 1backend: image: crufter/1backend:default-1-latest # Use a version that matches your GPU architecture for GPU acceleration, e.g.: # crufter/1backend:cuda-12.2.0-latest # For available versions, see: # - https://hub.docker.com/r/crufter/1backend/tags # - The build file `1backend-docker-build.yaml` ports: - &quot;11337:11337&quot; volumes: # We mount the hostname to have a sensible fallback node URL - /etc/hostname:/etc/host_hostname:ro # We mount the docker socket so the backend can start containers - /var/run/docker.sock:/var/run/docker.sock # We mount a volume so data will be persisted - 1backend-data:/root/.1backend # Permits 1Backend access to GPU metrics. # Containers launched by 1Backend can still use GPU acceleration even if 1Backend lacks direct GPU access. # deploy: # resources: # reservations: # devices: # - driver: nvidia # count: all # capabilities: [gpu] environment: # Volume mounted by AI containers launched by 1Backend to access models downloaded by the 1Backend File Svc. - OB_VOLUME_NAME=1backend-data # # Enables GPU acceleration for NVIDIA GPUs. # This flag controls GPU access for AI containers launched by 1Backend. # # - OB_GPU_PLATFORM=cuda Put the above into a file called docker-compose.yaml in a folder on your computer and run it with the following command: docker compose up Once it's running​ After the containers successfully start, you can go to 127.0.0.1:3901 and log in with the Default Credentials. Configuring​ See the Backend Environment Variables and Frontend Environment Variables.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Frontend Environment Variables","type":0,"sectionRef":"#","url":"/docs/running-the-server/frontend-environment-variables","content":"Frontend Environment Variables BACKEND_ADDRESS​ In a publicly accessible setup should be something like https://singulatron-api.yourdomain.com. The point is that it must be accessible from the outside/browser.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Backend Environment Variables","type":0,"sectionRef":"#","url":"/docs/running-the-server/backend-environment-variables","content":"Backend Environment Variables OB_CONTACT_EMAIL​ Specifies the system-wide contact email address for operational and administrative use. This email is used in various backend components, including: ACME TLS certificate registration (e.g., Let's Encrypt)System notifications or future alerting mechanismsRecovery options for certain services that require a fallback contact While optional, it is strongly recommended to set this in production environments so you can receive: Expiration or renewal notices for HTTPS certificatesWarnings about rate limits or configuration issuesFuture administrative alerts from the system This address will not be used for login or user account purposes. OB_DB​ You can use this envar to make 1Backend actually use a database instead of local file storage to store data. OB_DB_PREFIX​ When specified, all tables in the database will be prefixed by this strings. Mostly useful for testing. PostgreSQL​ OB_DB=postgres OB_DB_DRIVER=&quot;postgres&quot; # or &quot;mysql&quot; OB_DB_CONNECTION_STRING=&quot;postgres://postgres:mysecretpassword@localhost:5432/mydatabase?sslmode=disable&quot; Naturally, you should change the details of the connection string to reflect your environment. OB_EDGE_PROXY​ When set to true, 1Backend will enable the edge proxy feature. This feature configures the system to listen for incoming HTTP and HTTPS traffic on ports 80 and 443, respectively. OB_EDGE_PROXY=true The edge proxy acts as a public-facing reverse proxy, handling domain-based routing and TLS termination for external requests. It is typically used to: Serve ACME HTTP-01 challenges (for automated TLS certificates, e.g., via Let's Encrypt) on port 80.Handle public HTTPS traffic on port 443, routing incoming domain-based requests to appropriate backends or services based on their domain. When OB_EDGE_PROXY is not set to true, 1Backend will not start these public-facing routers. Only the internal API server on the OB_SERVER_URL port (default: 11337) will be active. Typical Use Case: Use this flag when 1Backend is running as a publicly accessible server that needs to: Terminate TLS (HTTPS) at the edge.Serve automated certificates via ACME.Route external requests based on domain names. OB_EDGE_PROXY_TEST_MODE​ Enables test mode for the edge proxy: Turns off autocert.Uses HTTP for both the HTTP and HTTPS port. OB_EDGE_PROXY_HTTP_PORT​ Sets the HTTP port for the edge proxy. In production, this must be 80. Any other value is only for testing purposes. OB_EDGE_PROXY_HTTPS_PORT​ Sets the HTTPS port for the edge proxy. In production, this must be 443. Any other value is only useful in testing. OB_ENCRYPTION_KEY​ This key is used in the Secret Svc so secrets are encrypted at rest. OB_FOLDER​ When specified, all data (uploads, downloads, image resize caches, models etc.) will be stored in this folder. Defaults to ~/.1backend. OB_GPU_PLATFORM​ This envar is used to enabel GPU acceleration. Supported platforms: cuda Do not set this if your card doesn't support the given architecture or things will break. OB_LLM_HOST​ This flag is typically unnecessary since 1Backend retrieves the IP of the Docker bridge. Use it only as a corrective action. When 1Backend is running in a container, it needs to know how to address its siblings (other containers it started): Host | |-&gt; 1Backend Container |-&gt; Container Launched By 1Backend The 1Backend Container uses the envar OB_LLM_HOST to address Container Launched By 1Backend. Typically this value should be 172.17.0.1 if you are using the default docker network. If you are using an other network than default, use docker network inspect to find out the IP of your docker bridge for that network. Usually it's going to be 172.18.0.1. This envar is not needed if 1Backend runs directly on the host: Host With 1Backend | |-&gt; Container Launched By 1Backend OB_NODE_ID​ For information about this, please refer to the Registry Svc Node section OB_SERVER_URL​ The OB_SERVER_URL is the internally addressable (non-public-facing) URL of an 1Backend server. It should point to the local 1Backend instance on each physical node. Ideally, every node should have its own 1Backend instance. This envar should be set only for microservices built on 1Backend. The 1Backend server itself should use OB_SELF_URL. OB_SELF_URL​ Microservices use this to register themselves in the 1Backend registry. The 1Backend server uses this to address itself. OB_TEST​ Microservices and the 1Backend server uses this envar to detect if they are running as part of a test. When set to true, subsystems act accordingly: for example the datastore will prefix tables with random numbers to provide a unique and clean environment for each test. First startup is also significantly faster when this flag is enabled, as 1Backend uses bcrypt.MinCost instead of bcrypt.DefaultCost for password generation, and sets the RSA key size to 512 bits in test mode instead of the default 4096. OB_TOKEN_AUTO_REFRESH_OFF​ When set to true, clients are responsible for handling the refresh of expired tokens themselves. This overrides the default behavior, where expired tokens are automatically accepted and refreshed by the system. OB_TOKEN_EXPIRATION​ Specifies the duration before a token expires. Use formats like 5m for five minutes, 10h for ten hours, etc. OB_VOLUME_NAME​ This flag is typically unnecessary since 1Backend automatically detects the volume that is bound to /root/.1backend. Use it only as a corrective action. This envar is needed when 1Backend runs as a container next to containers it starts: Host | |-&gt; 1Backend Container |-&gt; Container Launched By 1Backend For the containers like llama-cpp to be able to read the models downloaded by 1Backend we they must both mount the same docker volume. An example of this can be seen in the root docker-compose.yaml file: OB_VOLUME_NAME=singulatron-data. So cycle goes like this: 1Backend container writes to /root/.1backend, which is mounted to the volume singulatron-dataAssets (which are basically downloaded files) will be passed to containers created by 1Backend by mounting files in singulatron-data.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Running the 1Backend server locally","type":0,"sectionRef":"#","url":"/docs/running-the-server/locally","content":"Running the 1Backend server locally The easiest way to run 1Backend is to use Docker Compose. Using Docker Compose​ The easiest way to run this is to clone the repo, step into the repo root and run: git clone git@github.com:1backend/1backend.git cd 1backend docker compose up # or use the -d flag to run it in the background # docker compose up -d The docker-compose-yaml in the root folder is designed to build and run the current code. For a more production ready Docker Compose file see the Running the 1Backend server with Docker Compose and prebuilt images. Once it's running in Docker Compose​ After the containers successfully start, you can go to http://127.0.0.1:3901 and log in with the Default Credentials. Running natively (Go &amp; Angular)​ If you have both Go and Angular installed on your computer, the easiest way to dip your feet into 1Backend is to run things locally. Running the backend natively (with Go)​ cd server; go run main.go Running the frontend natively (with Angular)​ cd desktop/workspaces/angular-app/; npm run start Once it's running on the host​ After the both the backend and frontend starts, you can go to http://127.0.0.1:4200 and log in with the Default Credentials. Administration​ Local files​ By default 1Backend uses the folder ~/.1backend on your machine for data tables, file downloads, file uploads. The ~/.1backend/cliConfig.yaml file is where the oo CLI stores all its data. Download &amp; Uploads​ Downloads and uploads are managed by the File Svc, and by default are stored here: ~/.1backend/downloads ~/.1backend/uploads Data files​ By default 1Backend uses local gzipped json files to store database entries. Data access across 1Backend is interface based so the this implementation can be easily swapped out for PostgreSQL and other database backends. These files are located at ls ~/.1backend/data Each file is prefixed by the owner service slug, so the User Svc users table becomes userSvcUsers. If you want to view the contents of a file: cat ~/.1backend/data/userSvcUsers.zip | gzip -dc # or if you jave jq installed cat ~/.1backend/data/userSvcUsers.zip | gzip -dc | jq ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Once the 1Backend server is running","type":0,"sectionRef":"#","url":"/docs/running-the-server/using","content":"Once the 1Backend server is running Using the 1Backend UI​ Depending on how you started 1Backend, you can access the 1Backend UI on http://127.0.0.1:3901 (if you use Docker Compose), or http://127.0.0.1:4200 (if you use Angular). Using the 1Backend CLI​ See the oo CLI page for more information about CLI usage. Default Credentials​ Unless you configured otherwise, you can log in with the following default credentials: username: 1backend password: changeme ","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"System design guidelines","type":0,"sectionRef":"#","url":"/docs/writing-custom-services/system-design-guidelines","content":"System design guidelines 1Backend doesn't force you to use any particular patterns, languages, stacks, databases, or even conventions. 1Backend services themselves however follow some light conventions. API naming guidelines​ List* endpoints​ It is advised that endpoints returning entities are called ListEntities, eg. ListMessages. Do not create read/query endpoints that return a single entity unless you have good reasons to do so. The list endpoints should have a few standard filters ideally: ids field​ The field ids should enable single and multiread by ID queries in list endpoints. Pagination​ Pagination should happen with these fields in the top level of the List request: { &quot;limit&quot;: 10, &quot;__comment_limit&quot;: &quot;Limit is the maximum number of users to return.&quot;, &quot;afterTime&quot;: &quot;2023-01-01T00:00:00Z&quot;, &quot;__comment_afterTime&quot;: &quot;AfterTime is a time in RFC3339 format. It is used to paginate the results when the `orderBy` is set to `createdAt` or `updatedAt`. The results will be returned after this time.&quot;, &quot;order&quot;: &quot;desc&quot;, &quot;orderBy&quot;: &quot;createdAt&quot;, &quot;count&quot;: false, &quot;__comment_count&quot;: &quot;Count is a flag that indicates if the count of the users should be returned.&quot; } createdAt &amp; updatedAt ordering​ Extracting data from microservices into external systems (like BigQuery) must respect service boundaries. Since each service owns its data, the only supported way to access it is through its API—making efficient pagination essential. Traditional offset-based pagination can be inefficient in distributed systems, so 1Backend services use cursor-based pagination via the afterTime field. Pagination using createdAt allows clients to perform a full scan of all records. This is typically done in ascending order, starting from the earliest entry. Pagination using updatedAt is ideal for retrieving recently modified records. When sorted in descending order, it helps clients fetch the latest updates efficiently. Save* endpoints​ For endpoints that create or update entities, it’s recommended to use a unified SaveEntities naming convention (e.g., SaveMessages). While separating Create and Update operations allows for more precise request schemas (since the required fields may differ), 1Backend favors the following principles: Minimize the number of endpoints — simpler APIs are easier to maintain and evolve. Prioritize idempotency — Create endpoints typically aren't idempotent, while Save can be designed to be. Optimize for batch operations — network calls are costly. Design endpoints to handle multiple entities at once. This not only improves efficiency but also makes it easier to scale or create specialized multi-* versions of your endpoint when performance demands arise. IDs​ Ids are by convention prefixed by a shorthand inspired by the entity name, think thread IDs being prefixed by thr_.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"},{"title":"Your first service","type":0,"sectionRef":"#","url":"/docs/writing-custom-services/your-first-service","content":"Your first service While 1Backend itself is written in Go, services that run on it can be written in any language. A service only needs a few things to fully function: Register a user account, just like a human user. For details, see the User Svc.Register its instance in the registry so 1Backend knows where to route requests. A Go example​ The following Go service demonstrates these steps: Registers itself as a user with the slug basic-svcRegisters or updates its URL (http://127.0.0.1:9111) in the Registry. You may notice that the following code uses a &quot;Go SDK&quot;—this is simply a set of convenience functions built on top of the 1Backend API. 1Backend is language-agnostic and can be used with any language, even if no SDK is available in the repository. The full code, including tests, is available in the examples directory. // &lt;!-- INCLUDE: ../../../examples/go/services/basic/internal/basic_service.go --&gt; package basicservice import ( &quot;context&quot; &quot;net/http&quot; openapi &quot;github.com/1backend/1backend/clients/go&quot; basic &quot;github.com/1backend/1backend/examples/go/services/basic/internal/types&quot; sdk &quot;github.com/1backend/1backend/sdk/go&quot; &quot;github.com/1backend/1backend/sdk/go/auth&quot; &quot;github.com/1backend/1backend/sdk/go/boot&quot; &quot;github.com/1backend/1backend/sdk/go/client&quot; &quot;github.com/1backend/1backend/sdk/go/datastore&quot; &quot;github.com/1backend/1backend/sdk/go/infra&quot; &quot;github.com/gorilla/mux&quot; &quot;github.com/pkg/errors&quot; ) const RolePetManager = &quot;basic-svc:pet:manager&quot; type BasicService struct { Options *boot.Options token string userSvcPublicKey string dataStoreFactory infra.DataStoreFactory petsStore datastore.DataStore credentialStore datastore.DataStore Router *mux.Router } type Options struct { Test bool ServerUrl string SelfUrl string } func NewService(options *boot.Options) (*BasicService, error) { options.LoadEnvars() dconf := infra.DataStoreConfig{} if options.Test { dconf.Test = true dconf.TablePrefix = sdk.Id(&quot;t&quot;) } service := &amp;BasicService{ Options: options, } dsf, err := infra.NewDataStoreFactory(dconf) if err != nil { return nil, errors.Wrap(err, &quot;cannot create datastore factory&quot;) } service.dataStoreFactory = dsf petStore, err := dsf.Create(&quot;basicSvcPets&quot;, &amp;basic.Pet{}) if err != nil { return nil, err } service.petsStore = petStore service.registerAccount() service.registerRoutes() return service, nil } func (service *BasicService) Start() error { client := client.NewApiClientFactory(service.Options.ServerUrl). Client(client.WithToken(service.token)) _, _, err := client.RegistrySvcAPI. RegisterInstance(context.Background()). Body(openapi.RegistrySvcRegisterInstanceRequest{ Url: service.Options.SelfUrl, }).Execute() if err != nil { return errors.Wrap(err, &quot;cannot register instance&quot;) } return nil } func (service *BasicService) registerAccount() error { credentialStore, err := service.dataStoreFactory.Create(&quot;basicSvcCredentials&quot;, &amp;auth.Credential{}) if err != nil { return errors.Wrap(err, &quot;cannot create credential store&quot;) } service.credentialStore = credentialStore obClient := client.NewApiClientFactory(service.Options.ServerUrl).Client() token, err := boot.RegisterServiceAccount( obClient.UserSvcAPI, &quot;basic-svc&quot;, &quot;Basic Svc&quot;, service.credentialStore, ) if err != nil { return errors.Wrap(err, &quot;cannot register service&quot;) } service.token = token.Token obClient = client.NewApiClientFactory(service.Options.ServerUrl). Client(client.WithToken(service.token)) _, _, err = obClient.RegistrySvcAPI. RegisterInstance(context.Background()). Body(openapi.RegistrySvcRegisterInstanceRequest{ Url: service.Options.SelfUrl, }).Execute() if err != nil { return errors.Wrap(err, &quot;cannot register instance&quot;) } pk, _, err := obClient. UserSvcAPI.GetPublicKey(context.Background()). Execute() if err != nil { return err } service.userSvcPublicKey = pk.PublicKey return nil } func (service *BasicService) registerRoutes() { appl := service.Options.Middlewares service.Router = mux.NewRouter() service.Router.HandleFunc(&quot;/basic-svc/pet&quot;, appl(func(w http.ResponseWriter, r *http.Request) { service.SavePet(w, r) })). Methods(&quot;OPTIONS&quot;, &quot;PUT&quot;) service.Router.HandleFunc(&quot;/basic-svc/pets&quot;, appl(func(w http.ResponseWriter, r *http.Request) { service.ListPets(w, r) })). Methods(&quot;OPTIONS&quot;, &quot;POST&quot;) service.Router.HandleFunc(&quot;/basic-svc/error&quot;, appl(func(w http.ResponseWriter, r *http.Request) { service.Error(w, r) })). Methods(&quot;OPTIONS&quot;, &quot;POST&quot;) } // &lt;!-- /INCLUDE --&gt; Make sure to run it with the appropriate environment variables: OB_SERVER_URL=http://127.0.0.1:11337 OB_SELF_URL=http://127.0.0.1:9111 go run main.go Once it's running, you'll be able to call the 1Backend server proxy, which will forward the request to your basic service: # 127.0.0.1:11337 here is the address of the 1Backend server $ curl 127.0.0.1:11337/basic-svc/hello {&quot;hello&quot;: &quot;world&quot;} This means you don't have to expose your basic service to the outside world—only the 1Backend server needs to be accessible. Let's recap how the proxying works: Service registers an account, acquires the basic-svc slug.Service calls the 1Backend Registry Svc to tell the system an instance of the Basic service is available under the URL http://127.0.0.1:9111When you send a request to the 1Backend server with a path like 127.0.0.1:11337/basic-svc/hello, the first section of the path is interpreted as a user account slug. The server checks what instances are owned by that slug and routes the request to one of those instances. $ oo instance ls ID URL STATUS OWNER SLUG LAST HEARTBEAT inst_eHFTNvAlk9 http://127.0.0.1:9111 Healthy basic-svc 10s ago Things to understand​ Instance registration​ Like most other things on the platform, service instances are owned by a user account slug. When the basic service calls RegisterInstance, the host will be associated with the basic-svc slug. Updates to this host won’t be possible unless the caller is the basic service itself or an admin. In essence, the service becomes the owner of that URL. This is the same ownership model used throughout the 1Backend system.","keywords":"ai  llm  free gpt  gpt  open-source  open source  ai framework  ai server","version":"Next"}],"options":{"id":"default"}}